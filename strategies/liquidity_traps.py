"""
LiquidityTraps Professional Trading Strategy v3.0
Institution-Grade Implementation with Ultra-Low Latency Architecture

Author: NEXUS Trading System
Version: 3.0 Professional
License: Proprietary
"""

from __future__ import annotations

import asyncio
import logging
import time
from datetime import datetime, timezone
from decimal import Decimal, ROUND_HALF_UP
from enum import Enum, auto
from typing import Dict, List, Optional, Protocol, Tuple, Union
from collections import deque, defaultdict
from dataclasses import dataclass, field
import numpy as np
from functools import lru_cache
import pandas as pd

# ============================================================================
# NEXUS AI INTEGRATION - Production imports with fallback
# ============================================================================

import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    from nexus_ai import (
        AuthenticatedMarketData as NexusAuthenticatedMarketData,
        NexusSecurityLayer,
        ProductionSequentialPipeline,
    )
    NEXUS_AI_AVAILABLE = True
except ImportError:
    NEXUS_AI_AVAILABLE = False
    class NexusSecurityLayer:
        def __init__(self, **kwargs):
            self.enabled = False
    class ProductionSequentialPipeline:
        def __init__(self, **kwargs):
            self.enabled = False

# MQScore 6D Engine Integration
try:
    from MQScore_6D_Engine_v3 import (
        MQScoreEngine,
        MQScoreComponents,
        MQScoreConfig
    )
    HAS_MQSCORE = True
    logging.info("âœ“ MQScore 6D Engine available for market quality assessment")
except ImportError as e:
    HAS_MQSCORE = False
    MQScoreEngine = None
    MQScoreComponents = None
    MQScoreConfig = None
    logging.warning(f"MQScore Engine not available: {e} - using basic filters only")

# Strategy category fallback (no direct nexus_ai import here)

class StrategyCategory(Enum):
    TREND_FOLLOWING = "Trend Following"
    MEAN_REVERSION = "Mean Reversion"
    MOMENTUM = "Momentum"
    VOLATILITY_BREAKOUT = "Volatility Breakout"
    SCALPING = "Scalping"
    ARBITRAGE = "Arbitrage"
    MARKET_MAKING = "Market Making"
    EVENT_DRIVEN = "Event-Driven"
    BREAKOUT = "Breakout"
    VOLUME_PROFILE = "Volume Profile"
    ORDER_FLOW = "Order Flow"

# Configure structured logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s.%(msecs)03d | %(name)s | %(levelname)s | %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ============================================================================
# TYPE DEFINITIONS & DATA MODELS
# ============================================================================

class SignalType(Enum):
    """Trading signal types with semantic meaning"""
    LONG = auto()
    SHORT = auto()
    CLOSE_LONG = auto()
    CLOSE_SHORT = auto()
    HOLD = auto()
    
class MarketRegime(Enum):
    """Market regime classification for adaptive behavior"""
    TRENDING_UP = auto()
    TRENDING_DOWN = auto()
    RANGING = auto()
    HIGH_VOLATILITY = auto()
    LOW_VOLATILITY = auto()
    UNKNOWN = auto()

class OrderType(Enum):
    """Order execution types"""
    MARKET = auto()
    LIMIT = auto()
    STOP = auto()
    STOP_LIMIT = auto()

@dataclass
class MarketData:
    """
    Market data container with validation
    Uses slots for memory efficiency
    """
    instrument: str
    timestamp: datetime
    open: Decimal
    high: Decimal
    low: Decimal
    close: Decimal
    volume: int
    bid: Decimal
    ask: Decimal
    bid_size: int
    ask_size: int
    
    def __post_init__(self):
        """Validate market data integrity"""
        if self.high < self.low:
            # Instead of raising an exception, fix the issue by setting them equal to avoid crashes
            if self.high == self.low:
                # Both are the same, no issue
                pass
            else:
                # Swap values to ensure high >= low
                object.__setattr__(self, 'high', max(self.high, self.low))
                object.__setattr__(self, 'low', min(self.high, self.low))
        if self.volume < 0:
            # Set volume to 0 if negative to avoid crashes
            object.__setattr__(self, 'volume', 0)
        if self.bid > self.ask:
            # Instead of raising an exception, fix the issue by setting bid to ask price
            # This handles cases of inverted markets
            if self.bid == self.ask:
                # Both are the same, no issue
                pass
            else:
                # Align bid and ask to prevent inverted spread
                object.__setattr__(self, 'bid', min(self.bid, self.ask))
                object.__setattr__(self, 'ask', max(self.bid, self.ask))
    
    @property
    def spread(self) -> Decimal:
        """Calculate bid-ask spread"""
        return self.ask - self.bid
    
    @property
    def mid_price(self) -> Decimal:
        """Calculate mid price"""
        return (self.bid + self.ask) / Decimal('2')
    
    @property
    def typical_price(self) -> Decimal:
        """Calculate typical price (HLC/3)"""
        return (self.high + self.low + self.close) / Decimal('3')

@dataclass(frozen=True, slots=True)
class Signal:
    """
    Immutable trading signal with comprehensive metadata
    """
    strategy: str
    instrument: str
    timestamp: datetime
    signal_type: SignalType
    confidence: float  # 0.0 to 1.0
    price: Decimal
    quantity: int
    stop_loss: Optional[Decimal] = None
    take_profit: Optional[Decimal] = None
    metadata: Dict = field(default_factory=dict)
    
    def __post_init__(self):
        """Validate signal parameters"""
        if not 0 <= self.confidence <= 1:
            raise ValueError(f"Invalid confidence: {self.confidence}")
        if self.quantity < 0:
            raise ValueError(f"Invalid quantity: {self.quantity}")

@dataclass
class Position:
    """
    Active position tracking with P&L calculation
    """
    instrument: str
    side: SignalType
    quantity: int
    entry_price: Decimal
    entry_time: datetime
    stop_loss: Optional[Decimal] = None
    take_profit: Optional[Decimal] = None
    current_price: Decimal = Decimal('0')
    realized_pnl: Decimal = Decimal('0')
    fees_paid: Decimal = Decimal('0')
    
    @property
    def unrealized_pnl(self) -> Decimal:
        """Calculate unrealized P&L"""
        if self.side == SignalType.LONG:
            return (self.current_price - self.entry_price) * Decimal(self.quantity)
        elif self.side == SignalType.SHORT:
            return (self.entry_price - self.current_price) * Decimal(self.quantity)
        return Decimal('0')
    
    @property
    def total_pnl(self) -> Decimal:
        """Calculate total P&L including fees"""
        return self.unrealized_pnl + self.realized_pnl - self.fees_paid
    
    @property
    def pnl_percentage(self) -> Decimal:
        """Calculate P&L as percentage"""
        if self.entry_price == 0:
            return Decimal('0')
        return (self.total_pnl / (self.entry_price * Decimal(self.quantity))) * Decimal('100')

# ============================================================================
# CORE STRATEGY COMPONENTS
# ============================================================================

class AdaptiveThresholdCalculator:
    """
    Dynamic threshold calculation based on market conditions
    Replaces static thresholds with volatility-adaptive logic
    """
    
    def __init__(self, base_threshold: float = 0.5, lookback: int = 20):
        self.base_threshold = Decimal(str(base_threshold))
        self.lookback = lookback
        self.price_history = deque(maxlen=lookback)
        self.volume_history = deque(maxlen=lookback)
        self._volatility_cache = {}
        
    def update(self, market_data: MarketData) -> None:
        """Update price and volume history"""
        self.price_history.append(market_data.typical_price)
        self.volume_history.append(market_data.volume)
        self._volatility_cache.clear()  # Invalidate cache
    
    @lru_cache(maxsize=1)
    def calculate_volatility(self) -> Decimal:
        """Calculate rolling volatility with caching"""
        if len(self.price_history) < 2:
            return Decimal('0.01')  # Default volatility
            
        returns = []
        for i in range(1, len(self.price_history)):
            denominator = self.price_history[i-1]
            if denominator == 0:
                # Skip this return calculation to avoid division by zero
                continue
            ret = (self.price_history[i] - self.price_history[i-1]) / denominator
            returns.append(float(ret))
        
        return Decimal(str(np.std(returns))) if returns else Decimal('0.01')
    
    def get_trap_threshold(self) -> Decimal:
        """Calculate adaptive trap threshold based on volatility"""
        volatility = self.calculate_volatility()
        
        # Adaptive threshold: higher volatility = higher threshold
        # This prevents false signals in volatile markets
        adaptive_multiplier = Decimal('1') + (volatility * Decimal('10'))
        return self.base_threshold * adaptive_multiplier
    
    def get_volume_multiplier(self) -> Decimal:
        """Calculate adaptive volume multiplier"""
        if len(self.volume_history) < 5:
            return Decimal('1.5')
        
        recent_vol = np.mean(list(self.volume_history)[-5:])
        historical_vol = np.mean(list(self.volume_history))
        
        if historical_vol == 0:
            return Decimal('1.5')
        
        vol_ratio = Decimal(str(recent_vol / historical_vol))
        
        # Adaptive multiplier: adjust based on recent volume trends
        if vol_ratio > Decimal('1.2'):  # Already high volume
            return Decimal('1.2')
        elif vol_ratio < Decimal('0.8'):  # Low volume
            return Decimal('2.0')
        else:
            return Decimal('1.5')

class MarketMicrostructureAnalyzer:
    """
    Analyzes market microstructure for better signal quality
    """
    
    def __init__(self):
        self.order_flow_imbalance = deque(maxlen=100)
        self.spread_history = deque(maxlen=100)
        self.trade_intensity = deque(maxlen=100)
    
    def update(self, market_data: MarketData) -> None:
        """Update microstructure metrics"""
        # Order flow imbalance
        total_size = market_data.bid_size + market_data.ask_size
        if total_size > 0:
            imbalance = (market_data.bid_size - market_data.ask_size) / total_size
            self.order_flow_imbalance.append(imbalance)
        
        # Spread tracking
        self.spread_history.append(float(market_data.spread))
        
        # Trade intensity (volume-weighted)
        if market_data.volume > 0:
            intensity = market_data.volume * float(market_data.typical_price)
            self.trade_intensity.append(intensity)
    
    def get_liquidity_score(self) -> float:
        """
        Calculate liquidity score (0-1)
        Higher score = better liquidity
        """
        if len(self.spread_history) < 10:
            return 0.5
        
        # Components of liquidity score
        avg_spread = np.mean(list(self.spread_history))
        spread_stability = 1 / (1 + np.std(list(self.spread_history)))
        
        if self.trade_intensity:
            intensity_score = min(1.0, np.mean(list(self.trade_intensity)) / 1000000)
        else:
            intensity_score = 0.5
        
        # Weighted liquidity score
        liquidity_score = (
            0.4 * (1 / (1 + avg_spread)) +  # Tighter spread = better
            0.3 * spread_stability +          # Stable spread = better
            0.3 * intensity_score             # Higher intensity = better
        )
        
        return max(0.0, min(1.0, liquidity_score))
    
    def detect_adverse_selection(self) -> bool:
        """
        Detect potential adverse selection in order flow
        Returns True if adverse selection detected
        """
        if len(self.order_flow_imbalance) < 20:
            return False
        
        recent_imbalance = list(self.order_flow_imbalance)[-10:]
        
        # Check for persistent one-sided flow (potential informed trading)
        if all(x > 0.3 for x in recent_imbalance) or all(x < -0.3 for x in recent_imbalance):
            return True
        
        # Check for sudden imbalance spike
        if abs(recent_imbalance[-1]) > 0.7:
            return True
        
        return False

class EnhancedLiquidityTrapDetector:
    """
    Advanced liquidity trap detection with microstructure analysis
    """
    
    def __init__(self, lookback_period: int = 15):
        self.lookback_period = lookback_period
        self.threshold_calculator = AdaptiveThresholdCalculator()
        self.microstructure = MarketMicrostructureAnalyzer()
        self.price_levels = deque(maxlen=lookback_period)
        self.volume_profile = {}
        self.trap_history = deque(maxlen=100)
        
    def update_volume_profile(self, market_data: MarketData) -> None:
        """Build volume profile for support/resistance detection"""
        price_level = float(market_data.typical_price)
        rounded_level = round(price_level, 2)  # Round to nearest cent
        
        # Use a tuple to store volume and timestamp for better cleanup
        if rounded_level not in self.volume_profile:
            self.volume_profile[rounded_level] = {
                'volume': 0,
                'timestamp': market_data.timestamp
            }
        self.volume_profile[rounded_level]['volume'] += market_data.volume
        self.volume_profile[rounded_level]['timestamp'] = market_data.timestamp
        
        # Cleanup old levels (keep only recent 100 levels)
        if len(self.volume_profile) > 100:
            # Sort by timestamp and remove oldest entries
            sorted_levels = sorted(
                self.volume_profile.items(),
                key=lambda x: x[1]['timestamp']
            )
            # Remove the oldest level
            if sorted_levels:
                oldest_level = sorted_levels[0][0]
                del self.volume_profile[oldest_level]
    
    def identify_key_levels(self) -> Tuple[Optional[Decimal], Optional[Decimal]]:
        """
        Identify key support and resistance levels from volume profile
        """
        if len(self.volume_profile) < 10:
            return None, None
        
        # Sort levels by volume (high volume = key level)
        sorted_levels = sorted(
            self.volume_profile.items(),
            key=lambda x: x[1]['volume'],  # Access the 'volume' key in the dict
            reverse=True
        )
        
        # Get top 20% as key levels
        n_key_levels = max(2, len(sorted_levels) // 5)
        key_levels = [Decimal(str(level)) for level, _ in sorted_levels[:n_key_levels]]
        
        if not self.price_levels:
            return None, None
        
        current_price = self.price_levels[-1]
        
        # Find nearest support and resistance
        support = None
        resistance = None
        
        for level in key_levels:
            if level < current_price and (support is None or level > support):
                support = level
            elif level > current_price and (resistance is None or level < resistance):
                resistance = level
        
        return support, resistance
    
    def detect_trap(self, market_data: MarketData) -> Optional[Signal]:
        """
        Detect liquidity traps with enhanced logic
        """
        # Update components
        self.threshold_calculator.update(market_data)
        self.microstructure.update(market_data)
        self.price_levels.append(market_data.typical_price)
        self.update_volume_profile(market_data)
        
        if len(self.price_levels) < self.lookback_period:
            return None
        
        # Get adaptive thresholds
        trap_threshold = self.threshold_calculator.get_trap_threshold()
        volume_multiplier = self.threshold_calculator.get_volume_multiplier()
        
        # Identify key levels
        support, resistance = self.identify_key_levels()
        
        if resistance is None and support is None:
            return None
        
        # Check for adverse selection (potential trap)
        if self.microstructure.detect_adverse_selection():
            logger.warning(f"Adverse selection detected at {market_data.timestamp}")
        
        # Get liquidity score
        liquidity_score = self.microstructure.get_liquidity_score()
        
        # Calculate average volume
        recent_volumes = []
        if hasattr(self.threshold_calculator, 'volume_history'):
            recent_volumes = list(self.threshold_calculator.volume_history)[-20:]
        avg_volume = np.mean(recent_volumes) if recent_volumes else market_data.volume
        
        signal = None
        
        # Bull Trap Detection (False breakout above resistance)
        if resistance and market_data.high > resistance:
            breakout_magnitude = (market_data.high - resistance) / resistance if resistance != 0 else Decimal('0')
            
            # Check if price reversed back below resistance
            if market_data.close < resistance:
                denominator = market_data.high - resistance
                if denominator == 0:
                    # Skip this calculation to avoid division by zero
                    return None
                reversal_magnitude = (market_data.high - market_data.close) / denominator
                
                # Enhanced confirmation criteria
                if (reversal_magnitude > float(trap_threshold) and
                    market_data.volume > avg_volume * float(volume_multiplier) and
                    liquidity_score > 0.4 and
                    not self.microstructure.detect_adverse_selection()):
                    
                    confidence = min(0.95, float(reversal_magnitude) * liquidity_score)
                    
                    signal = Signal(
                        strategy="enhanced_liquidity_traps",
                        instrument=market_data.instrument,
                        timestamp=market_data.timestamp,
                        signal_type=SignalType.SHORT,
                        confidence=confidence,
                        price=market_data.close,
                        quantity=0,  # Will be determined by risk manager
                        stop_loss=market_data.high * Decimal('1.005'),  # 0.5% above high
                        take_profit=support if support else market_data.close * Decimal('0.98'),
                        metadata={
                            "trap_type": "BULL_TRAP",
                            "resistance_level": float(resistance),
                            "breakout_magnitude": float(breakout_magnitude),
                            "reversal_magnitude": float(reversal_magnitude),
                            "liquidity_score": liquidity_score,
                            "volume_ratio": market_data.volume / avg_volume
                        }
                    )
        
        # Bear Trap Detection (False breakout below support)
        elif support and market_data.low < support:
            breakout_magnitude = (support - market_data.low) / support if support != 0 else Decimal('0')
            
            # Check if price reversed back above support
            if market_data.close > support:
                denominator = support - market_data.low
                if denominator == 0:
                    # Skip this calculation to avoid division by zero
                    return None
                reversal_magnitude = (market_data.close - market_data.low) / denominator
                
                # Enhanced confirmation criteria
                if (reversal_magnitude > float(trap_threshold) and
                    market_data.volume > avg_volume * float(volume_multiplier) and
                    liquidity_score > 0.4 and
                    not self.microstructure.detect_adverse_selection()):
                    
                    confidence = min(0.95, float(reversal_magnitude) * liquidity_score)
                    
                    signal = Signal(
                        strategy="enhanced_liquidity_traps",
                        instrument=market_data.instrument,
                        timestamp=market_data.timestamp,
                        signal_type=SignalType.LONG,
                        confidence=confidence,
                        price=market_data.close,
                        quantity=0,  # Will be determined by risk manager
                        stop_loss=market_data.low * Decimal('0.995'),  # 0.5% below low
                        take_profit=resistance if resistance else market_data.close * Decimal('1.02'),
                        metadata={
                            "trap_type": "BEAR_TRAP",
                            "support_level": float(support),
                            "breakout_magnitude": float(breakout_magnitude),
                            "reversal_magnitude": float(reversal_magnitude),
                            "liquidity_score": liquidity_score,
                            "volume_ratio": market_data.volume / avg_volume
                        }
                    )
        
        # Record trap for analysis
        if signal:
            self.trap_history.append({
                "timestamp": market_data.timestamp,
                "type": signal.metadata["trap_type"],
                "confidence": signal.confidence
            })
            
            logger.info(f"Trap detected: {signal.metadata['trap_type']} "
                       f"at {market_data.close} with confidence {signal.confidence:.2f}")
        
        return signal

# ============================================================================
# RISK MANAGEMENT SYSTEM
# ============================================================================

import threading

class InstitutionalRiskManager:
    """
    Comprehensive risk management system with multiple layers of control
    """
    
    def __init__(self,
                 max_position_size: Decimal = Decimal('100000'),
                 max_portfolio_risk: Decimal = Decimal('0.02'),  # 2% max portfolio risk
                 max_correlation_risk: Decimal = Decimal('0.6'),
                 max_daily_loss: Decimal = Decimal('5000'),
                 max_positions: int = 10):
        
        self.max_position_size = max_position_size
        self.max_portfolio_risk = max_portfolio_risk
        self.max_correlation_risk = max_correlation_risk
        self.max_daily_loss = max_daily_loss
        self.max_positions = max_positions
        
        self.positions: Dict[str, Position] = {}
        self.daily_pnl = Decimal('0')
        self.risk_metrics = {}
        self.correlation_matrix = {}
        self.var_calculator = ValueAtRiskCalculator()
        
        # Circuit breakers
        self.circuit_breaker_triggered = False
        self.max_consecutive_losses = 5
        self.consecutive_losses = 0
        
        # Thread safety
        self._lock = threading.RLock()
        
        logger.info("Institutional Risk Manager initialized")
    
    def calculate_position_size(self,
                               signal: Signal,
                               account_balance: Decimal,
                               market_data: MarketData) -> int:
        """
        Calculate position size using Kelly Criterion with safety factor
        """
        if self.circuit_breaker_triggered:
            logger.warning("Circuit breaker active - no new positions")
            return 0
        
        if len(self.positions) >= self.max_positions:
            logger.warning("Maximum positions reached")
            return 0
        
        # Check daily loss limit
        if self.daily_pnl <= -self.max_daily_loss:
            logger.warning("Daily loss limit reached")
            self.circuit_breaker_triggered = True
            return 0
        
        # Kelly Criterion with safety factor
        win_rate = 0.55  # Historical win rate (should be calculated dynamically)
        avg_win = Decimal('0.015')  # Average win size
        avg_loss = Decimal('0.01')  # Average loss size
        
        # Kelly percentage = (p * b - q) / b
        # where p = win probability, q = loss probability, b = win/loss ratio
        p = Decimal(str(win_rate))
        q = Decimal('1') - p
        b = avg_win / avg_loss
        
        kelly_pct = (p * b - q) / b
        
        # Apply safety factor (use 25% of Kelly)
        safe_kelly = kelly_pct * Decimal('0.25')
        
        # Adjust for signal confidence
        risk_adjusted_pct = safe_kelly * Decimal(str(signal.confidence))
        
        # Calculate position size
        risk_amount = account_balance * risk_adjusted_pct
        
        # Adjust for volatility
        volatility = self.var_calculator.calculate_volatility([market_data])
        volatility_adjustment = Decimal('1') / (Decimal('1') + volatility)
        
        position_value = risk_amount * volatility_adjustment
        position_size = int(position_value / market_data.close)
        
        # Apply limits
        max_size = int(self.max_position_size / market_data.close)
        position_size = min(position_size, max_size)
        
        # Minimum position size
        if position_size < 1:
            position_size = 0
        
        logger.info(f"Position size calculated: {position_size} "
                   f"(Kelly: {kelly_pct:.2%}, Adjusted: {risk_adjusted_pct:.2%})")
        
        return position_size
    
    def check_correlation_risk(self, new_instrument: str) -> bool:
        """
        Check if adding new position would exceed correlation risk limits
        """
        if new_instrument not in self.correlation_matrix:
            return True  # No correlation data, allow trade
        
        total_correlation = Decimal('0')
        for instrument in self.positions:
            if instrument in self.correlation_matrix.get(new_instrument, {}):
                correlation = self.correlation_matrix[new_instrument][instrument]
                total_correlation += abs(Decimal(str(correlation)))
        
        avg_correlation = total_correlation / len(self.positions) if self.positions else Decimal('0')
        
        if avg_correlation > self.max_correlation_risk:
            logger.warning(f"Correlation risk too high: {avg_correlation:.2f}")
            return False
        
        return True
    
    def update_position(self, position: Position, market_data: MarketData) -> None:
        """Update position with current market data"""
        with self._lock:
            position.current_price = market_data.close
            
            # Check stop loss
            if position.stop_loss:
                if position.side == SignalType.LONG and market_data.close <= position.stop_loss:
                    self.close_position(position.instrument, market_data.close, "Stop loss hit")
                elif position.side == SignalType.SHORT and market_data.close >= position.stop_loss:
                    self.close_position(position.instrument, market_data.close, "Stop loss hit")
            
            # Check take profit
            if position.take_profit:
                if position.side == SignalType.LONG and market_data.close >= position.take_profit:
                    self.close_position(position.instrument, market_data.close, "Take profit hit")
                elif position.side == SignalType.SHORT and market_data.close <= position.take_profit:
                    self.close_position(position.instrument, market_data.close, "Take profit hit")
    
    def close_position(self, instrument: str, exit_price: Decimal, reason: str) -> None:
        """Close position and update P&L"""
        with self._lock:
            if instrument not in self.positions:
                return
            
            position = self.positions[instrument]
            
            # Calculate realized P&L
            if position.side == SignalType.LONG:
                pnl = (exit_price - position.entry_price) * Decimal(position.quantity)
            else:
                pnl = (position.entry_price - exit_price) * Decimal(position.quantity)
            
            position.realized_pnl = pnl
            self.daily_pnl += pnl
            
            # Update consecutive losses
            if pnl < 0:
                self.consecutive_losses += 1
                if self.consecutive_losses >= self.max_consecutive_losses:
                    self.circuit_breaker_triggered = True
                    logger.error(f"Circuit breaker triggered: {self.consecutive_losses} consecutive losses")
            else:
                self.consecutive_losses = 0
            
            logger.info(f"Position closed: {instrument} - P&L: {pnl:.2f} - Reason: {reason}")
            
            del self.positions[instrument]
    
    def get_portfolio_risk_metrics(self) -> Dict:
        """Calculate comprehensive portfolio risk metrics"""
        with self._lock:
            if not self.positions:
                return {
                    "total_exposure": 0,
                    "portfolio_var": 0,
                    "sharpe_ratio": 0,
                    "max_drawdown": 0
                }
            
            total_exposure = sum(
                p.current_price * Decimal(p.quantity)
                for p in self.positions.values()
            )
            
            # Calculate portfolio VaR
            position_values = [p.total_pnl for p in self.positions.values()]
            portfolio_var = self.var_calculator.calculate_var(position_values) if position_values else Decimal('0')
            
            return {
                "total_exposure": float(total_exposure),
                "portfolio_var": float(portfolio_var),
                "daily_pnl": float(self.daily_pnl),
                "num_positions": len(self.positions),
                "circuit_breaker": self.circuit_breaker_triggered,
                "consecutive_losses": self.consecutive_losses
            }

class ValueAtRiskCalculator:
    """
    Calculate Value at Risk (VaR) for risk assessment
    """
    
    def __init__(self, confidence_level: float = 0.95, lookback_days: int = 252):
        self.confidence_level = confidence_level
        self.lookback_days = lookback_days
        self.returns_history = deque(maxlen=lookback_days)
    
    def calculate_var(self, position_values: List[Decimal]) -> Decimal:
        """Calculate portfolio VaR using historical simulation"""
        if not position_values or not self.returns_history:
            return Decimal('0')
        
        portfolio_value = sum(position_values)
        
        # Historical VaR
        returns = sorted(self.returns_history)
        if not returns:
            return Decimal('0')
        
        var_index = int((1 - self.confidence_level) * len(returns))
        # Ensure var_index is within bounds
        var_index = max(0, min(var_index, len(returns) - 1))
        var_return = Decimal(str(returns[var_index])) if var_index < len(returns) else Decimal('0')
        
        return portfolio_value * abs(var_return)
    
    def calculate_volatility(self, market_data_list: List[MarketData]) -> Decimal:
        """Calculate historical volatility"""
        if len(market_data_list) < 2:
            return Decimal('0.01')  # Default volatility
        
        returns = []
        for i in range(1, len(market_data_list)):
            prev_close = market_data_list[i-1].close
            if prev_close == 0:
                # Skip this return calculation to avoid division by zero
                continue
            ret = (market_data_list[i].close - prev_close) / prev_close
            returns.append(float(ret))
        
        return Decimal(str(np.std(returns))) if returns else Decimal('0.01')

# ============================================================================
# ORDER MANAGEMENT SYSTEM
# ============================================================================

class OrderManagementSystem:
    """
    Professional order management with execution algorithms
    """
    
    def __init__(self):
        self.pending_orders = {}
        self.executed_orders = {}
        self.order_id_counter = 0
        self.execution_algos = {
            "TWAP": self.execute_twap,
            "VWAP": self.execute_vwap,
            "ICEBERG": self.execute_iceberg
        }
    
    def create_order(self,
                    signal: Signal,
                    position_size: int,
                    execution_algo: str = "TWAP") -> Dict:
        """Create new order from signal"""
        self.order_id_counter += 1
        order_id = f"ORD_{self.order_id_counter:06d}"
        
        order = {
            "order_id": order_id,
            "instrument": signal.instrument,
            "side": signal.signal_type,
            "quantity": position_size,
            "price": signal.price,
            "order_type": OrderType.LIMIT,
            "status": "PENDING",
            "created_at": signal.timestamp,
            "execution_algo": execution_algo,
            "filled_quantity": 0,
            "avg_fill_price": Decimal('0'),
            "metadata": signal.metadata
        }
        
        self.pending_orders[order_id] = order
        logger.info(f"Order created: {order_id} - {signal.signal_type.name} {position_size} @ {signal.price}")
        
        return order
    
    async def execute_order(self, order_id: str, market_data: MarketData) -> bool:
        """Execute order using specified algorithm"""
        if order_id not in self.pending_orders:
            return False
        
        order = self.pending_orders[order_id]
        algo = order.get("execution_algo", "TWAP")
        
        if algo in self.execution_algos:
            success = await self.execution_algos[algo](order, market_data)
            
            if success:
                order["status"] = "EXECUTED"
                self.executed_orders[order_id] = order
                del self.pending_orders[order_id]
                logger.info(f"Order executed: {order_id}")
                return True
        
        return False
    
    async def execute_twap(self, order: Dict, market_data: MarketData) -> bool:
        """Time-Weighted Average Price execution"""
        # Simplified TWAP - in production, this would slice the order over time
        slices = 10  # Number of time slices
        slice_size = order["quantity"] // slices
        
        # Simulate execution (in production, this would interact with exchange)
        order["filled_quantity"] = order["quantity"]
        order["avg_fill_price"] = market_data.mid_price
        
        return True
    
    async def execute_vwap(self, order: Dict, market_data: MarketData) -> bool:
        """Volume-Weighted Average Price execution"""
        # Simplified VWAP - in production, this would follow volume patterns
        order["filled_quantity"] = order["quantity"]
        order["avg_fill_price"] = market_data.typical_price
        
        return True
    
    async def execute_iceberg(self, order: Dict, market_data: MarketData) -> bool:
        """Iceberg order execution (show only small portion)"""
        visible_size = max(1, order["quantity"] // 20)  # Show 5% of order
        
        # Simulate execution
        order["filled_quantity"] = order["quantity"]
        order["avg_fill_price"] = market_data.mid_price
        
        return True

# ============================================================================
# PERFORMANCE ANALYTICS
# ============================================================================

class PerformanceAnalytics:
    """
    Comprehensive performance tracking and analysis
    """
    
    def __init__(self):
        self.trades = []
        self.equity_curve = []
        self.metrics = {}
        self.benchmark_returns = []
    
    def record_trade(self, trade: Dict) -> None:
        """Record completed trade for analysis"""
        self.trades.append({
            **trade,
            "timestamp": datetime.now(timezone.utc)
        })
        
        # Update equity curve
        if self.trades:
            total_pnl = sum(t.get("pnl", 0) for t in self.trades)
            self.equity_curve.append(total_pnl)
    
    def calculate_metrics(self) -> Dict:
        """Calculate comprehensive performance metrics"""
        if not self.trades:
            return {}
        
        # Basic metrics
        total_trades = len(self.trades)
        winning_trades = [t for t in self.trades if t.get("pnl", 0) > 0]
        losing_trades = [t for t in self.trades if t.get("pnl", 0) < 0]
        
        win_rate = len(winning_trades) / total_trades if total_trades > 0 else 0
        
        # P&L metrics
        total_pnl = sum(t.get("pnl", 0) for t in self.trades)
        avg_win = np.mean([t["pnl"] for t in winning_trades]) if winning_trades else 0
        avg_loss = np.mean([t["pnl"] for t in losing_trades]) if losing_trades else 0
        
        # Risk metrics
        returns = [t.get("pnl", 0) / t.get("position_value", 1) for t in self.trades]
        sharpe_ratio = self.calculate_sharpe_ratio(returns)
        max_drawdown = self.calculate_max_drawdown()
        
        # Advanced metrics
        profit_factor = abs(sum(t["pnl"] for t in winning_trades) / 
                          sum(t["pnl"] for t in losing_trades)) if losing_trades else float('inf')
        
        self.metrics = {
            "total_trades": total_trades,
            "win_rate": win_rate,
            "total_pnl": total_pnl,
            "avg_win": avg_win,
            "avg_loss": avg_loss,
            "profit_factor": profit_factor,
            "sharpe_ratio": sharpe_ratio,
            "max_drawdown": max_drawdown,
            "avg_trade_duration": self.calculate_avg_duration(),
            "best_trade": max(self.trades, key=lambda x: x.get("pnl", 0))["pnl"] if self.trades else 0,
            "worst_trade": min(self.trades, key=lambda x: x.get("pnl", 0))["pnl"] if self.trades else 0
        }
        
        return self.metrics
    
    def calculate_sharpe_ratio(self, returns: List[float], risk_free_rate: float = 0.02) -> float:
        """Calculate Sharpe ratio"""
        if not returns or len(returns) < 2:
            return 0.0
        
        excess_returns = [r - risk_free_rate/252 for r in returns]  # Daily risk-free rate
        
        avg_excess_return = np.mean(excess_returns)
        std_return = np.std(excess_returns)
        
        if std_return == 0:
            return 0.0
        
        return (avg_excess_return / std_return) * np.sqrt(252)  # Annualized
    
    def calculate_max_drawdown(self) -> float:
        """Calculate maximum drawdown"""
        if not self.equity_curve:
            return 0.0
        
        peak = self.equity_curve[0]
        max_dd = 0.0
        
        for value in self.equity_curve:
            if value > peak:
                peak = value
            drawdown = (peak - value) / peak if peak != 0 else 0
            max_dd = max(max_dd, drawdown)
        
        return max_dd
    
    def calculate_avg_duration(self) -> float:
        """Calculate average trade duration in hours"""
        if not self.trades:
            return 0.0
        
        durations = []
        for trade in self.trades:
            if "entry_time" in trade and "exit_time" in trade:
                duration = (trade["exit_time"] - trade["entry_time"]).total_seconds() / 3600
                durations.append(duration)
        
        return np.mean(durations) if durations else 0.0
    
    def generate_report(self) -> str:
        """Generate performance report"""
        metrics = self.calculate_metrics()
        
        report = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              PERFORMANCE ANALYTICS REPORT                         â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ TRADING METRICS                                                   â•‘
â•‘ â”œâ”€ Total Trades:        {metrics.get('total_trades', 0):>8}                          â•‘
â•‘ â”œâ”€ Win Rate:            {metrics.get('win_rate', 0):>7.1%}                          â•‘
â•‘ â”œâ”€ Profit Factor:       {metrics.get('profit_factor', 0):>8.2f}                          â•‘
â•‘                                                                    â•‘
â•‘ PROFIT & LOSS                                                     â•‘
â•‘ â”œâ”€ Total P&L:           ${metrics.get('total_pnl', 0):>10,.2f}                     â•‘
â•‘ â”œâ”€ Average Win:         ${metrics.get('avg_win', 0):>10,.2f}                     â•‘
â•‘ â”œâ”€ Average Loss:        ${metrics.get('avg_loss', 0):>10,.2f}                     â•‘
â•‘ â”œâ”€ Best Trade:          ${metrics.get('best_trade', 0):>10,.2f}                     â•‘
â•‘ â”œâ”€ Worst Trade:         ${metrics.get('worst_trade', 0):>10,.2f}                     â•‘
â•‘                                                                    â•‘
â•‘ RISK METRICS                                                       â•‘
â•‘ â”œâ”€ Sharpe Ratio:        {metrics.get('sharpe_ratio', 0):>8.2f}                          â•‘
â•‘ â”œâ”€ Max Drawdown:        {metrics.get('max_drawdown', 0):>7.1%}                          â•‘
â•‘ â””â”€ Avg Trade Duration:  {metrics.get('avg_trade_duration', 0):>6.1f} hrs                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
        return report

# ============================================================================
# ADAPTIVE PARAMETER OPTIMIZATION - Real Performance-Based Learning
# ============================================================================


class AdaptiveParameterOptimizer:
    """Self-contained adaptive parameter optimization using real trade results."""
    def __init__(self, strategy_name: str):
        self.strategy_name = strategy_name
        self.performance_history = deque(maxlen=500)
        self.parameter_history = deque(maxlen=200)
        self.current_parameters = {
            "trap_threshold": 0.65,
            "confidence_threshold": 0.57,
            "lookback": 15.0,
        }
        self.adjustment_cooldown = 50
        self.trades_since_adjustment = 0
        logger.debug(f"Adaptive Parameter Optimizer initialized for {strategy_name}")

    def record_trade(self, trade_result: Dict[str, Any]):
        self.performance_history.append({
            "timestamp": time.time(),
            "pnl": trade_result.get("pnl", 0.0),
            "confidence": trade_result.get("confidence", 0.5),
            "volatility": trade_result.get("volatility", 0.02),
            "parameters": self.current_parameters.copy(),
        })
        self.trades_since_adjustment += 1
        if self.trades_since_adjustment >= self.adjustment_cooldown:
            self._adapt_parameters(); self.trades_since_adjustment = 0

    def _adapt_parameters(self):
        if len(self.performance_history) < 20:
            return
        recent = list(self.performance_history)[-50:]
        win_rate = sum(1 for t in recent if t.get("pnl", 0) > 0) / len(recent)
        avg_pnl = sum(t.get("pnl", 0) for t in recent) / len(recent)
        avg_vol = sum(t.get("volatility", 0.02) for t in recent) / len(recent)

        # Adapt trap threshold by win rate
        if win_rate < 0.40:
            self.current_parameters["trap_threshold"] = min(0.85, self.current_parameters["trap_threshold"] * 1.06)
        elif win_rate > 0.65:
            self.current_parameters["trap_threshold"] = max(0.50, self.current_parameters["trap_threshold"] * 0.97)

        # Adapt lookback by pnl
        if avg_pnl < 0:
            self.current_parameters["lookback"] = min(60.0, self.current_parameters["lookback"] * 1.05)
        elif avg_pnl > 0:
            self.current_parameters["lookback"] = max(5.0, self.current_parameters["lookback"] * 0.98)

        # Adapt confidence threshold by volatility
        vol_ratio = (avg_vol / 0.02) if 0.02 else 1.0
        if vol_ratio > 1.5:
            self.current_parameters["confidence_threshold"] = min(0.85, self.current_parameters["confidence_threshold"] * 1.05)
        elif vol_ratio < 0.7:
            self.current_parameters["confidence_threshold"] = max(0.45, self.current_parameters["confidence_threshold"] * 0.98)

        self.parameter_history.append({
            "timestamp": time.time(),
            "win_rate": win_rate,
            "avg_pnl": avg_pnl,
            "avg_volatility": avg_vol,
            "parameters": self.current_parameters.copy(),
        })

        logger.info(
            f"ðŸ“Š {self.strategy_name} adapted: Trap={self.current_parameters['trap_threshold']:.2f}, "
            f"Lookback={self.current_parameters['lookback']:.0f}, "
            f"Conf={self.current_parameters['confidence_threshold']:.2f}, WinRate={win_rate:.1%}"
        )

    def get_current_parameters(self) -> Dict[str, float]:
        return self.current_parameters.copy()

    def get_adaptation_stats(self) -> Dict[str, Any]:
        return {
            "adaptations": len(self.parameter_history),
            "trades_recorded": len(self.performance_history),
            "current_parameters": self.current_parameters.copy(),
        }

# ============================================================================
# MAIN STRATEGY ORCHESTRATOR
# ============================================================================

class LiquidityTrapsOrchestrator:
    """
    Main strategy orchestrator that coordinates all components
    """
    
    def __init__(self, config: Optional[Dict] = None):
        """Initialize strategy with configuration"""
        self.config = config or {}
        
        # Adaptive learning
        self.adaptive_optimizer = AdaptiveParameterOptimizer("liquidity_traps")
        logger.debug("Adaptive parameter optimization enabled")
        
        # Initialize components
        self.detector = EnhancedLiquidityTrapDetector(
            lookback_period=self.config.get("lookback_period", 15)
        )
        self.risk_manager = InstitutionalRiskManager(
            max_position_size=Decimal(str(self.config.get("max_position_size", 100000))),
            max_portfolio_risk=Decimal(str(self.config.get("max_portfolio_risk", 0.02))),
            max_daily_loss=Decimal(str(self.config.get("max_daily_loss", 5000)))
        )
        self.oms = OrderManagementSystem()
        self.analytics = PerformanceAnalytics()
        
        # Strategy state
        self.is_running = False
        self.last_signal_time = None
        self.min_signal_interval = 60  # Minimum seconds between signals
        
        logger.info("LiquidityTraps Orchestrator initialized")
    
    async def process_market_data(self, market_data: MarketData) -> Optional[Dict]:
        """
        Main processing pipeline for market data
        """
        try:
            # 1. Update positions with current prices
            # Acquire lock to ensure thread safety
            with self.risk_manager._lock:
                # Make a copy to avoid issues during iteration if positions change
                positions_copy = dict(self.risk_manager.positions)
            # Update each position (update_position handles locking internally)
            for position in positions_copy.values():
                self.risk_manager.update_position(position, market_data)
            
            # 2. Check for signal generation (with throttling)
            current_time = market_data.timestamp
            if self.last_signal_time:
                time_since_last = (current_time - self.last_signal_time).total_seconds()
                if time_since_last < self.min_signal_interval:
                    return None
            
            # 3. Detect liquidity trap (apply adapted params)
            params = self.adaptive_optimizer.get_current_parameters()
            try:
                # Update detector thresholds if available
                if hasattr(self.detector, "threshold_calculator") and hasattr(self.detector.threshold_calculator, "base_threshold"):
                    self.detector.threshold_calculator.base_threshold = Decimal(str(params.get("trap_threshold", 0.65)))
                if hasattr(self.detector, "lookback_period"):
                    self.detector.lookback_period = int(params.get("lookback", self.detector.lookback_period))
            except Exception:
                pass

            signal = self.detector.detect_trap(market_data)
            
            if signal:
                # Adaptive confidence gating
                if getattr(signal, "confidence", 0.0) < params.get("confidence_threshold", 0.57):
                    return None
                self.last_signal_time = current_time
                
                # 4. Calculate position size
                account_balance = Decimal(str(self.config.get("account_balance", 100000)))
                position_size = self.risk_manager.calculate_position_size(
                    signal, account_balance, market_data
                )
                
                if position_size > 0:
                    # 5. Check correlation risk
                    if self.risk_manager.check_correlation_risk(signal.instrument):
                        # 6. Create and execute order
                        order = self.oms.create_order(signal, position_size)
                        success = await self.oms.execute_order(order["order_id"], market_data)
                        
                        if success:
                            # 7. Create position
                            position = Position(
                                instrument=signal.instrument,
                                side=signal.signal_type,
                                quantity=position_size,
                                entry_price=market_data.mid_price,
                                entry_time=current_time,
                                stop_loss=signal.stop_loss,
                                take_profit=signal.take_profit
                            )
                            with self.risk_manager._lock:
                                self.risk_manager.positions[signal.instrument] = position
                            
                            # 8. Record trade
                            self.analytics.record_trade({
                                "instrument": signal.instrument,
                                "side": signal.signal_type.name,
                                "quantity": position_size,
                                "entry_price": float(market_data.mid_price),
                                "position_value": float(market_data.mid_price * position_size)
                            })
                            
                            return {
                                "action": "TRADE_EXECUTED",
                                "signal": signal,
                                "order": order,
                                "position": position
                            }
            
            # 9. Get portfolio metrics
            risk_metrics = self.risk_manager.get_portfolio_risk_metrics()
            
            return {
                "action": "NO_TRADE",
                "risk_metrics": risk_metrics
            }
            
        except Exception as e:
            logger.error(f"Error processing market data: {e}", exc_info=True)
            return None
    
    def get_performance_report(self) -> str:
        """Get performance analytics report"""
        return self.analytics.generate_report()
    
    def shutdown(self) -> None:
        """Gracefully shutdown strategy"""
        logger.info("Shutting down strategy...")
        
        # Close all positions
        # Acquire the lock to ensure thread safety during shutdown
        with self.risk_manager._lock:
            for instrument in list(self.risk_manager.positions.keys()):
                # Use the close_position method which handles lock internally
                # To avoid deadlock, we'll get the current price safely
                if instrument in self.risk_manager.positions:
                    current_price = self.risk_manager.positions[instrument].current_price
                    self.risk_manager.close_position(
                        instrument,
                        current_price,
                        "Strategy shutdown"
                    )
        
        # Cancel pending orders
        for order_id in list(self.oms.pending_orders.keys()):
            self.oms.pending_orders[order_id]["status"] = "CANCELLED"
        
        # Generate final report
        report = self.get_performance_report()
        logger.info(f"Final performance report:\n{report}")
        
        self.is_running = False
        logger.info("Strategy shutdown complete")

# ============================================================================
# NEXUS AI INTEGRATION ADAPTER
# ============================================================================
# Create the main strategy instance for NEXUS AI integration
# This allows the strategy to be imported and used directly
# Note: Class assignments will be added after class definition


# =====================================================================
# COMPREHENSIVE NEXUS ADAPTER V2 - LIQUIDITY TRAPS STRATEGY
# Complete Weeks 1-8 Integration: Thread Safety, Risk, ML, Execution
# =====================================================================

import threading
import secrets
import math
from typing import Any

# ============================================================================
# TIER 4 ENHANCEMENT: TTP CALCULATOR
# ============================================================================
class TTPCalculator:
    def __init__(self, config):
        self.config = config
        self.win_rate = 0.5
        self.trades_completed = 0
        self.winning_trades = 0
        self.ttp_history = deque(maxlen=1000)
    def calculate(self, market_data, signal_strength, historical_performance=None):
        base_probability = historical_performance if historical_performance else self.win_rate
        market_adj = self._calculate_market_adjustment(market_data)
        strength_mult = min(1.0, signal_strength / 100.0) if signal_strength else 0.5
        vol_penalty = self._calculate_volatility_penalty(market_data)
        ttp = base_probability * market_adj * strength_mult - vol_penalty
        ttp_value = max(0.0, min(1.0, ttp))
        self.ttp_history.append(ttp_value)
        return ttp_value
    def update_accuracy(self, signal, result):
        if result and isinstance(result, dict):
            self.trades_completed += 1
            if result.get('pnl', 0) > 0:
                self.winning_trades += 1
            self.win_rate = self.winning_trades / max(self.trades_completed, 1)
    def _calculate_market_adjustment(self, market_data):
        if not market_data or not isinstance(market_data, dict):
            return 0.8
        try:
            volatility = float(market_data.get('volatility', 1.0))
            volume = float(market_data.get('volume', 1000))
            volume_ratio = volume / 1000.0
            adjustment = max(0.5, min(1.2, 1.0 - (volatility - 1.0) * 0.1 + (volume_ratio - 1.0) * 0.05))
            return adjustment
        except:
            return 1.0
    def _calculate_volatility_penalty(self, market_data):
        if not market_data or not isinstance(market_data, dict):
            return 0.0
        try:
            volatility = float(market_data.get('volatility', 1.0))
            penalty = max(0.0, (volatility - 1.0) * 0.1)
            return penalty
        except:
            return 0.0

# ============================================================================
# TIER 4 ENHANCEMENT: CONFIDENCE THRESHOLD VALIDATOR
# ============================================================================
class ConfidenceThresholdValidator:
    def __init__(self, min_threshold=0.57):
        self.min_threshold = min_threshold
        self.rejected_count = 0
        self.accepted_count = 0
        self.rejection_history = deque(maxlen=100)
    def passes_threshold(self, confidence, ttp):
        try:
            conf_val = float(confidence) if confidence is not None else 0.5
            ttp_val = float(ttp) if ttp is not None else 0.5
            passes = conf_val >= self.min_threshold and ttp_val >= self.min_threshold
            if passes:
                self.accepted_count += 1
            else:
                self.rejected_count += 1
                self.rejection_history.append({'confidence': conf_val, 'ttp': ttp_val, 'timestamp': time.time()})
            return passes
        except:
            return False

# ============================================================================
# TIER 4 ENHANCEMENT: MULTI-LAYER PROTECTION FRAMEWORK
# ============================================================================
class MultiLayerProtectionFramework:
    def __init__(self, config):
        self.config = config
        self.kill_switch_active = False
        self.layer_violations = defaultdict(int)
        self.max_position_ratio = 0.05
        self.max_daily_loss_ratio = 0.10
        self.max_drawdown_limit = 0.15
    def validate_all_layers(self, signal, account_state, market_data, current_equity):
        try:
            layers = [
                ('pre_trade_compliance', self._layer_1_pre_trade_checks),
                ('risk_validation', self._layer_2_risk_validation),
                ('market_impact', self._layer_3_market_impact),
                ('liquidity_check', self._layer_4_liquidity_verification),
                ('counterparty_risk', self._layer_5_counterparty_risk),
                ('operational_health', self._layer_6_operational_risk),
                ('emergency_kill_switch', self._layer_7_kill_switch),
            ]
            for layer_name, layer_func in layers:
                result = layer_func(signal, account_state, market_data, current_equity)
                if not result:
                    self.layer_violations[layer_name] += 1
                    return False
            return True
        except:
            return False
    def _layer_1_pre_trade_checks(self, signal, account, market_data, equity):
        try:
            return not market_data.get('trading_halted', False)
        except:
            return True
    def _layer_2_risk_validation(self, signal, account, market_data, equity):
        try:
            position_size = abs(signal.get('size', 0) if signal else 0)
            max_position = equity * self.max_position_ratio
            daily_loss = float(account.get('daily_loss', 0))
            max_daily_loss = equity * self.max_daily_loss_ratio
            return position_size <= max_position and daily_loss < max_daily_loss
        except:
            return True
    def _layer_3_market_impact(self, signal, account, market_data, equity):
        try:
            bid = float(market_data.get('bid', 1.0))
            ask = float(market_data.get('ask', 1.0))
            spread = (ask - bid) / max(bid, 0.01)
            return spread < 0.01
        except:
            return True
    def _layer_4_liquidity_verification(self, signal, account, market_data, equity):
        try:
            order_size = abs(signal.get('size', 0) if signal else 0)
            bid_vol = float(market_data.get('total_bid_volume', 0))
            ask_vol = float(market_data.get('total_ask_volume', 0))
            available_liquidity = bid_vol + ask_vol
            return available_liquidity >= (order_size * 20) if order_size > 0 else True
        except:
            return True
    def _layer_5_counterparty_risk(self, signal, account, market_data, equity):
        try:
            return account.get('broker_healthy', True)
        except:
            return True
    def _layer_6_operational_risk(self, signal, account, market_data, equity):
        try:
            return account.get('system_healthy', True)
        except:
            return True
    def _layer_7_kill_switch(self, signal, account, market_data, equity):
        try:
            if self.kill_switch_active:
                return False
            max_drawdown = float(account.get('max_drawdown', 0))
            if max_drawdown > self.max_drawdown_limit:
                self.kill_switch_active = True
                return False
            return True
        except:
            return True

# ============================================================================
# TIER 4 ENHANCEMENT: ML ACCURACY TRACKER
# ============================================================================
class MLAccuracyTracker:
    def __init__(self, strategy_name):
        self.strategy_name = strategy_name
        self.predictions = deque(maxlen=1000)
        self.true_labels = deque(maxlen=1000)
        self.correct_predictions = 0
        self.total_predictions = 0
        self.performance_history = deque(maxlen=100)
    def update_trade_result(self, signal, trade_result):
        try:
            if not signal or not trade_result:
                return
            prediction = 1 if signal.get('signal', 0) > 0 else (0 if signal.get('signal', 0) < 0 else -1)
            actual = 1 if trade_result.get('pnl', 0) > 0 else (0 if trade_result.get('pnl', 0) < 0 else -1)
            self.predictions.append(float(signal.get('confidence', 0.5)))
            self.true_labels.append(actual)
            self.total_predictions += 1
            if prediction == actual:
                self.correct_predictions += 1
            self.performance_history.append({'timestamp': time.time(), 'accuracy': self.get_accuracy(), 'correct': prediction == actual, 'pnl': trade_result.get('pnl', 0)})
        except:
            pass
    def get_accuracy(self):
        return self.correct_predictions / max(self.total_predictions, 1)

# ============================================================================
# TIER 4 ENHANCEMENT: EXECUTION QUALITY TRACKER
# ============================================================================
class ExecutionQualityTracker:
    def __init__(self):
        self.slippage_history = deque(maxlen=100)
        self.latency_history = deque(maxlen=100)
        self.fill_rates = deque(maxlen=100)
        self.execution_events = deque(maxlen=500)
    def record_execution(self, expected_price, execution_price, latency_ms, fill_rate):
        try:
            slippage_bps = ((execution_price - expected_price) / max(expected_price, 0.01)) * 10000
            self.slippage_history.append(slippage_bps)
            self.latency_history.append(latency_ms)
            self.fill_rates.append(fill_rate)
            self.execution_events.append({'timestamp': time.time(), 'slippage_bps': slippage_bps, 'latency_ms': latency_ms, 'fill_rate': fill_rate})
        except:
            pass
    def get_quality_metrics(self):
        try:
            return {'avg_slippage_bps': float(np.mean(self.slippage_history)) if self.slippage_history else 0.0, 'avg_latency_ms': float(np.mean(self.latency_history)) if self.latency_history else 0.0, 'avg_fill_rate': float(np.mean(self.fill_rates)) if self.fill_rates else 0.0}
        except:
            return {}


class LiquidityTrapsNexusAdapterV2:
    """
    Complete NEXUS AI adapter for Liquidity Traps strategy - VERSION 2.
    
    Implements ALL 32 required components for 100% compliance:
    - Weeks 1-2: Thread safety, pipeline interface, error handling
    - Week 3: Configurable parameters with full risk management
    - Week 5: Kill switch with 3 triggers, VaR/CVaR, risk monitoring
    - Weeks 6-7: ML integration, feature store, ensemble support, drift detection
    - Week 8: Execution quality, fill handling, slippage tracking
    
    Advanced Features:
    - Volatility scaling for dynamic position sizing
    - Position entry/exit logic with scale-in and pyramiding
    - Leverage calculations with margin requirements
    - Position concentration tracking
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """Initialize complete adapter with comprehensive configuration."""
        # Configuration
        self.config = config or {}
        self.initial_capital = self.config.get('initial_capital', 100000.0)
        self.max_daily_loss = self.config.get('max_daily_loss', 2000.0)
        self.max_drawdown_pct = self.config.get('max_drawdown_pct', 0.15)
        self.max_consecutive_losses = self.config.get('max_consecutive_losses', 5)
        self.max_leverage = self.config.get('max_leverage', 3.0)
        
        # Thread safety - RLock for reentrant locking
        self._lock = threading.RLock()
        self._position_lock = threading.Lock()
        
        # Strategy instance - use existing orchestrator
        orchestrator_config = {
            'lookback_period': 15,
            'max_position_size': 100000,
            'max_portfolio_risk': 0.02,
            'max_daily_loss': self.max_daily_loss,
            'account_balance': self.initial_capital
        }
        self.orchestrator = LiquidityTrapsOrchestrator(orchestrator_config)
        
        # ============ MQSCORE 6D ENGINE: Market Quality Assessment ============
        if HAS_MQSCORE:
            mqscore_config = MQScoreConfig(
                min_buffer_size=20,
                cache_enabled=True,
                cache_ttl=300.0,
                ml_enabled=False,  # ML handled by pipeline, not in strategy
                base_weights={
                    'liquidity': 0.20,
                    'volatility': 0.15,
                    'momentum': 0.20,
                    'imbalance': 0.15,
                    'trend_strength': 0.20,
                    'noise_level': 0.10
                }
            )
            self.mqscore_engine = MQScoreEngine(config=mqscore_config)
            self.mqscore_threshold = 0.57  # Quality threshold for filtering
            logger.debug("MQScore 6D Engine initialized")
        else:
            self.mqscore_engine = None
            self.mqscore_threshold = 0.57
            logger.info("âš  MQScore not available - using basic filters only")
        
        # Performance tracking with dataclass
        self.metrics = PerformanceMetricsV2()
        
        # Risk management state
        self.daily_pnl = 0.0
        self.peak_equity = self.initial_capital
        self.current_equity = self.initial_capital
        self.consecutive_losses = 0
        self.kill_switch_active = False
        self.kill_switch_reason = None
        
        # Position management
        self.current_positions = {}
        self.pending_orders = {}
        self.position_history = deque(maxlen=1000)
        
        # Risk metrics (VaR/CVaR)
        self.returns_history = deque(maxlen=252)  # ~1 year of daily returns
        self.var_95 = 0.0
        self.var_99 = 0.0
        self.cvar_95 = 0.0
        self.cvar_99 = 0.0
        
        # ML Pipeline Integration (Weeks 6-7)
        self.ml_pipeline_connected = False
        self.ml_ensemble_models = []
        self.ml_predictions = deque(maxlen=100)
        self.ml_confidence_threshold = 0.57
        
        # Feature Store with caching (Week 7)
        self.feature_cache = {}
        self.feature_cache_ttl = 60  # seconds
        self.feature_cache_max_size = 1000
        self.feature_last_update = {}
        
        # Model drift detection (Week 7)
        self.baseline_accuracy = 0.0
        self.current_accuracy = 0.0
        self.drift_threshold = 0.15  # 15% degradation triggers alert
        self.drift_detected = False
        
        # ML Parameter Manager (Week 7)
        self.ml_parameter_manager = {
            'confidence_threshold': 0.57,
            'ml_weight': 0.3,
            'ensemble_agreement_threshold': 0.6,
            'min_prediction_samples': 10,
            'parameter_update_frequency': 50,  # Update every 50 predictions
            'learning_rate': 0.05,
            'momentum': 0.9,
            'adaptive_enabled': True
        }
        self.ml_parameter_history = deque(maxlen=200)
        self.ml_parameter_update_count = 0
        
        # Execution quality tracking (Week 8)
        self.execution_metrics = {
            'total_fills': 0,
            'partial_fills': 0,
            'full_fills': 0,
            'average_fill_time': 0.0,
            'average_slippage_bps': 0.0,
            'total_slippage_cost': 0.0,
            'fill_rate': 0.0,
            'cancel_rate': 0.0,
            'latency_p50': 0.0,
            'latency_p95': 0.0,
            'latency_p99': 0.0,
        }
        self.fill_times = deque(maxlen=1000)
        self.slippage_records = deque(maxlen=1000)
        self.latency_records = deque(maxlen=1000)
        
        # Volatility tracking for scaling
        self.volatility_window = deque(maxlen=20)
        self.realized_volatility = 0.02  # Default 2%
        
        # Position concentration tracking
        self.position_concentrations = {}
        self.max_single_position_pct = 0.15  # 15% max per position
        
        # ============ W1.1 & W1.3: Gap and Whipsaw Tracking ============
        self.last_close_price = None  # For gap detection
        self.reversal_history = deque(maxlen=100)  # For whipsaw detection
        
        # ============ TIER 4: Initialize 5 Components ============
        self.ttp_calculator = TTPCalculator(self.config)
        self.confidence_validator = ConfidenceThresholdValidator(min_threshold=0.57)
        self.protection_framework = MultiLayerProtectionFramework(self.config)
        self.ml_tracker = MLAccuracyTracker("LIQUIDITY_TRAPS")
        self.execution_quality_tracker = ExecutionQualityTracker()
        
        logger.debug("LiquidityTrapsNexusAdapterV2 initialized")
    
    # ========================================================================
    # REQUIRED PROTOCOL METHODS (Weeks 1-2)
    # ========================================================================
    
    def execute(self, market_data: Any, features: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Execute strategy with standardized return format for NEXUS compatibility.
        
        Required protocol method - returns {"signal": float, "confidence": float, "features": dict, "metadata": dict}
        """
        # Get detailed execution result
        detailed_result = self._execute_detailed(market_data, features)
        
        # ============ PACKAGE MQSCORE FEATURES FOR PIPELINE ML ============
        if features is None:
            features = {}
        
        # Add MQScore 6D components if available
        mqscore_components = detailed_result.get('mqscore_6d')
        mqscore_quality = detailed_result.get('mqscore_quality')
        
        if mqscore_components:
            features.update({
                "mqs_composite": mqscore_quality,
                "mqs_liquidity": mqscore_components["liquidity"],
                "mqs_volatility": mqscore_components["volatility"],
                "mqs_momentum": mqscore_components["momentum"],
                "mqs_imbalance": mqscore_components["imbalance"],
                "mqs_trend_strength": mqscore_components["trend_strength"],
                "mqs_noise_level": mqscore_components["noise_level"],
            })
        
        # Convert to standardized format
        if detailed_result.get('action') == 'HOLD':
            return {
                'signal': 0.0,
                'confidence': 0.0,
                'features': features,  # For pipeline ML
                'metadata': {
                    'action': 'HOLD',
                    'reason': detailed_result.get('reason', 'No signal'),
                    'strategy': 'liquidity_traps_v2',
                    'mqscore_enabled': mqscore_quality is not None,
                    'mqscore_quality': mqscore_quality,
                    'mqscore_6d': mqscore_components,
                }
            }
        else:
            # Convert action to signal
            action_signal = 1.0 if detailed_result.get('action') == 'BUY' else -1.0
            
            return {
                'signal': action_signal,
                'confidence': detailed_result.get('confidence', 0.5),
                'features': features,  # For pipeline ML
                'metadata': {
                    'action': detailed_result.get('action'),
                    'symbol': detailed_result.get('symbol'),
                    'size': detailed_result.get('size'),
                    'entry_price': detailed_result.get('entry_price'),
                    'stop_loss': detailed_result.get('stop_loss'),
                    'take_profit': detailed_result.get('take_profit'),
                    'strategy': 'liquidity_traps_v2',
                    'order_id': detailed_result.get('order_id'),
                    'mqscore_enabled': mqscore_quality is not None,
                    'mqscore_quality': mqscore_quality,
                    'mqscore_6d': mqscore_components,
                    'metadata': detailed_result.get('metadata', {}),
                    'risk_metrics': detailed_result.get('risk_metrics', {}),
                    'execution_details': detailed_result
                }
            }
    
    def _execute_detailed(self, market_data: Any, features: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Execute strategy with comprehensive risk management and ML integration.
        
        Internal method - returns detailed execution plan.
        """
        with self._lock:
            try:
                # Check kill switch
                if self.kill_switch_active:
                    return {
                        'action': 'HOLD',
                        'reason': f'Kill switch active: {self.kill_switch_reason}',
                        'kill_switch': True
                    }
                
                # Convert market data to strategy format
                if isinstance(market_data, dict):
                    md = self._convert_market_data_to_object(market_data, features)
                else:
                    md = market_data
                
                # Update volatility for scaling
                self._update_volatility(md)
                
                # ============ MQSCORE 6D: MARKET QUALITY FILTERING ============
                mqscore_quality = None
                mqscore_components = None
                
                if self.mqscore_engine:
                    try:
                        import pandas as pd
                        price = float(md.close)
                        market_df = pd.DataFrame([{
                            'open': float(getattr(md, 'open', price)),
                            'close': price,
                            'high': float(md.high),
                            'low': float(md.low),
                            'volume': md.volume,
                            'timestamp': md.timestamp
                        }])
                        
                        mqscore_result = self.mqscore_engine.calculate_mqscore(market_df)
                        mqscore_quality = mqscore_result.composite_score
                        mqscore_components = {
                            "liquidity": mqscore_result.liquidity,
                            "volatility": mqscore_result.volatility,
                            "momentum": mqscore_result.momentum,
                            "imbalance": mqscore_result.imbalance,
                            "trend_strength": mqscore_result.trend_strength,
                            "noise_level": mqscore_result.noise_level,
                        }
                        
                        # FILTER: Reject if market quality below threshold
                        if mqscore_quality < self.mqscore_threshold:
                            logger.info(f"MQScore REJECTED: {md.instrument} quality={mqscore_quality:.3f} < {self.mqscore_threshold}")
                            return {
                                'action': 'HOLD',
                                'reason': f'Market quality too low: {mqscore_quality:.3f}',
                                'mqscore_quality': mqscore_quality,
                                'mqscore_6d': mqscore_components,
                                'filtered_by_mqscore': True
                            }
                        
                        logger.debug(f"MQScore PASSED: {md.instrument} quality={mqscore_quality:.3f}")
                        
                    except Exception as e:
                        logger.warning(f"MQScore calculation error: {e} - proceeding without MQScore filter")
                        mqscore_quality = None
                
                # ============ W1.1 CRITICAL FIX: GAP EVENT DETECTION ============
                gap_event = self._detect_gap_event(md)
                if gap_event and gap_event.get('significant'):
                    logger.info(f"Gap detected: {gap_event['type']} of {gap_event['size_pct']:.2f}%")
                    # Gap creates potential trap opportunity
                    # Store for analysis but don't block signal generation
                
                # ============ W1.4 CRITICAL FIX: REGIME FITNESS FILTERING ============
                regime_fitness = self._check_regime_fitness(mqscore_components)
                if regime_fitness < 0.50:  # Poor market conditions for traps
                    logger.info(f"Regime fitness too low: {regime_fitness:.2f} (need >0.50)")
                    return {
                        'action': 'HOLD',
                        'reason': f'Poor regime fitness for traps: {regime_fitness:.2f}',
                        'mqscore_quality': mqscore_quality,
                        'mqscore_6d': mqscore_components,
                        'regime_fitness': regime_fitness,
                        'filtered_by_regime': True
                    }
                logger.debug(f"Regime fitness PASSED: {regime_fitness:.2f}")
                
                # Check risk limits before generating signals
                risk_check = self._check_risk_limits()
                if risk_check['stop_trading']:
                    self._activate_kill_switch(risk_check['reason'])
                    return {
                        'action': 'HOLD',
                        'reason': f'Risk limit breached: {risk_check["reason"]}',
                        'risk_limits': risk_check
                    }
                
                # Generate base strategy signal using orchestrator
                import asyncio
                try:
                    loop = asyncio.get_running_loop()
                    result = loop.run_until_complete(self.orchestrator.process_market_data(md))
                except RuntimeError:
                    result = asyncio.run(self.orchestrator.process_market_data(md))
                
                if not result or 'signal' not in result:
                    return {'action': 'HOLD', 'reason': 'No signal generated'}
                
                signal_info = result['signal']
                confidence = float(signal_info.confidence)
                
                # ML enhancement if connected (Week 6-7)
                if self.ml_pipeline_connected and features:
                    confidence = self._enhance_signal_with_ml(signal_info, features, confidence)
                
                # Convert signal type to action
                if signal_info.signal_type == SignalType.LONG:
                    action = 'BUY'
                    signal_strength = confidence
                elif signal_info.signal_type == SignalType.SHORT:
                    action = 'SELL'
                    signal_strength = -confidence
                else:
                    return {'action': 'HOLD', 'reason': 'No directional signal', 'confidence': confidence}
                
                # Calculate position size with volatility scaling
                position_size = self._calculate_position_size_with_scaling(
                    confidence, float(md.close)
                )
                
                if position_size <= 0:
                    return {
                        'action': 'HOLD',
                        'reason': 'Position size calculation returned zero',
                        'signal_confidence': confidence
                    }
                
                # Calculate entry/exit levels
                entry_exit = self._calculate_entry_exit_logic(signal_info, md, confidence)
                
                # Prepare execution with quality tracking
                execution_plan = {
                    'action': action,
                    'symbol': md.instrument,
                    'size': position_size,
                    'entry_price': float(signal_info.price),
                    'stop_loss': entry_exit['stop_loss'],
                    'take_profit': entry_exit['take_profit'],
                    'trailing_stop': entry_exit['trailing_stop'],
                    'confidence': confidence,
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'strategy': 'liquidity_traps_v2',
                    'metadata': {
                        'trap_type': signal_info.metadata.get('trap_type', 'UNKNOWN'),
                        'support_level': signal_info.metadata.get('support_level'),
                        'resistance_level': signal_info.metadata.get('resistance_level'),
                        'liquidity_score': signal_info.metadata.get('liquidity_score', 0.0),
                        'volume_ratio': signal_info.metadata.get('volume_ratio', 1.0)
                    },
                    'risk_metrics': self._get_current_risk_metrics(),
                    'execution_quality_target': {
                        'max_slippage_bps': 10,
                        'target_fill_time_ms': 500,
                        'min_fill_rate': 0.95
                    }
                }
                
                # Track order for fill monitoring
                order_id = self._generate_order_id()
                self.pending_orders[order_id] = {
                    'plan': execution_plan,
                    'submitted_at': time.time(),
                    'status': 'PENDING'
                }
                execution_plan['order_id'] = order_id
                
                return execution_plan
                
            except Exception as e:
                logger.error(f"Error in execute(): {e}", exc_info=True)
                self.metrics.error_count += 1
                return {
                    'action': 'HOLD',
                    'reason': f'Execution error: {str(e)}',
                    'error': True
                }
    
    def get_category(self) -> str:
        """Return strategy category for classification."""
        return "ORDERFLOW_LIQUIDITY"
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """
        Get comprehensive performance metrics including risk, execution, and ML metrics.
        
        Required protocol method - provides complete performance overview.
        """
        with self._lock:
            # Calculate additional derived metrics
            self._update_var_cvar()
            
            leverage_metrics = self._calculate_leverage_metrics()
            
            return {
                # Core performance
                'total_trades': self.metrics.total_trades,
                'winning_trades': self.metrics.winning_trades,
                'losing_trades': self.metrics.losing_trades,
                'win_rate': self.metrics.win_rate,
                'total_pnl': self.metrics.total_pnl,
                'average_pnl': self.metrics.average_return,
                
                # Risk metrics (Week 5)
                'daily_pnl': self.daily_pnl,
                'current_equity': self.current_equity,
                'peak_equity': self.peak_equity,
                'current_drawdown': (self.peak_equity - self.current_equity) / self.peak_equity if self.peak_equity > 0 else 0,
                'max_drawdown': self.metrics.max_drawdown,
                'consecutive_losses': self.consecutive_losses,
                'kill_switch_active': self.kill_switch_active,
                'kill_switch_reason': self.kill_switch_reason,
                
                # VaR/CVaR metrics (Week 5)
                'var_95': self.var_95,
                'var_99': self.var_99,
                'cvar_95': self.cvar_95,
                'cvar_99': self.cvar_99,
                
                # Advanced performance
                'sharpe_ratio': self.metrics.sharpe_ratio,
                'profit_factor': self.metrics.profit_factor,
                'largest_win': self.metrics.largest_win,
                'largest_loss': self.metrics.largest_loss,
                'average_win': self.metrics.average_win,
                'average_loss': self.metrics.average_loss,
                
                # ML metrics (Week 6-7)
                'ml_pipeline_connected': self.ml_pipeline_connected,
                'ml_predictions_count': len(self.ml_predictions),
                'ml_baseline_accuracy': self.baseline_accuracy,
                'ml_current_accuracy': self.current_accuracy,
                'ml_drift_detected': self.drift_detected,
                'ml_drift_threshold': self.drift_threshold,
                
                # Feature store metrics (Week 7)
                'feature_cache_size': len(self.feature_cache),
                'feature_cache_hit_rate': self._calculate_cache_hit_rate(),
                
                # Execution metrics (Week 8)
                'execution_quality': self.execution_metrics,
                'average_slippage_bps': self._calculate_average_slippage(),
                'fill_rate': self._calculate_fill_rate(),
                'partial_fill_rate': self._calculate_partial_fill_rate(),
                
                # Position management
                'active_positions': len(self.current_positions),
                'pending_orders': len(self.pending_orders),
                'position_concentrations': self.position_concentrations,
                
                # Leverage metrics
                'leverage_metrics': leverage_metrics,
                
                # System metrics
                'realized_volatility': self.realized_volatility,
                'error_count': self.metrics.error_count,
                'validation_failures': self.metrics.validation_failures,
            }
    
    # ========================================================================
    # KILL SWITCH & RISK MANAGEMENT (Week 5)
    # ========================================================================
    
    def _check_risk_limits(self) -> Dict[str, Any]:
        """Check all risk limits and return status."""
        reasons = []
        
        # Check daily loss limit
        if self.daily_pnl < -self.max_daily_loss:
            reasons.append(f'Daily loss limit breached: ${self.daily_pnl:.2f} < -${self.max_daily_loss:.2f}')
        
        # Check drawdown limit
        current_dd = (self.peak_equity - self.current_equity) / self.peak_equity if self.peak_equity > 0 else 0
        if current_dd > self.max_drawdown_pct:
            reasons.append(f'Drawdown limit breached: {current_dd:.1%} > {self.max_drawdown_pct:.1%}')
        
        # Check consecutive losses
        if self.consecutive_losses >= self.max_consecutive_losses:
            reasons.append(f'Consecutive losses limit: {self.consecutive_losses} >= {self.max_consecutive_losses}')
        
        return {
            'stop_trading': len(reasons) > 0,
            'reason': '; '.join(reasons) if reasons else None,
            'daily_pnl': self.daily_pnl,
            'current_drawdown': current_dd,
            'consecutive_losses': self.consecutive_losses
        }
    
    def _activate_kill_switch(self, reason: str):
        """Activate kill switch and halt trading."""
        self.kill_switch_active = True
        self.kill_switch_reason = reason
        logger.critical(f"ðŸ›‘ KILL SWITCH ACTIVATED: {reason}")
        
        # Close all positions
        self._emergency_close_all_positions()
    
    def _emergency_close_all_positions(self):
        """Emergency close all open positions."""
        with self._position_lock:
            for symbol, position in list(self.current_positions.items()):
                logger.warning(f"Emergency closing position: {symbol}")
                self.current_positions.pop(symbol, None)
    
    def _update_var_cvar(self):
        """Calculate Value at Risk and Conditional VaR."""
        if len(self.returns_history) < 30:
            return
        
        returns_list = sorted(list(self.returns_history))
        n = len(returns_list)
        
        # VaR at 95% confidence (5th percentile)
        var_95_idx = int(n * 0.05)
        self.var_95 = abs(returns_list[var_95_idx]) if var_95_idx < n else 0
        
        # VaR at 99% confidence (1st percentile)
        var_99_idx = int(n * 0.01)
        self.var_99 = abs(returns_list[var_99_idx]) if var_99_idx < n else 0
        
        # CVaR (average of losses beyond VaR)
        if var_95_idx > 0:
            self.cvar_95 = abs(sum(returns_list[:var_95_idx]) / var_95_idx)
        if var_99_idx > 0:
            self.cvar_99 = abs(sum(returns_list[:var_99_idx]) / var_99_idx)
    
    def _get_current_risk_metrics(self) -> Dict[str, float]:
        """Get current risk metrics for order metadata."""
        return {
            'var_95': self.var_95,
            'var_99': self.var_99,
            'cvar_95': self.cvar_95,
            'cvar_99': self.cvar_99,
            'current_drawdown': (self.peak_equity - self.current_equity) / self.peak_equity if self.peak_equity > 0 else 0,
            'daily_pnl': self.daily_pnl,
            'consecutive_losses': self.consecutive_losses,
        }
    
    # ========================================================================
    # ML PIPELINE INTEGRATION (Weeks 6-7)
    # ========================================================================
    
    def connect_to_pipeline(self, pipeline_config: Dict[str, Any]) -> bool:
        """
        Connect to ML pipeline with ensemble support.
        
        Week 6 requirement - enables ML-enhanced signal generation.
        """
        try:
            self.ml_pipeline_connected = True
            self.ml_ensemble_models = pipeline_config.get('ensemble_models', [])
            self.ml_confidence_threshold = pipeline_config.get('confidence_threshold', 0.57)
            
            # Initialize baseline accuracy for drift detection
            self.baseline_accuracy = pipeline_config.get('baseline_accuracy', 0.70)
            self.current_accuracy = self.baseline_accuracy
            
            logger.debug(f"ML Pipeline connected with {len(self.ml_ensemble_models)} models")
            return True
            
        except Exception as e:
            logger.error(f"Failed to connect to ML pipeline: {e}")
            self.ml_pipeline_connected = False
            return False
    
    def _enhance_signal_with_ml(self, signal_info: Any, features: Dict, base_confidence: float) -> float:
        """Enhance signal with ML predictions (Week 6-7)."""
        try:
            # Get ML prediction from ensemble
            ml_prediction = self._get_ml_ensemble_prediction(features)
            
            if ml_prediction is None:
                return base_confidence
            
            # Blend base signal with ML prediction (30% ML, 70% base)
            ml_weight = 0.3
            base_weight = 0.7
            
            enhanced_confidence = (
                base_confidence * base_weight +
                ml_prediction['confidence'] * ml_weight
            )
            
            # Check if ML agrees with signal direction
            signal_direction = 'BUY' if signal_info.signal_type == SignalType.LONG else 'SELL'
            ml_agrees = (signal_direction == ml_prediction['direction'])
            
            if not ml_agrees:
                enhanced_confidence *= 0.7  # Reduce confidence if ML disagrees
            
            # Store prediction for drift detection
            self.ml_predictions.append({
                'timestamp': time.time(),
                'prediction': ml_prediction,
                'actual_direction': signal_direction,
                'confidence': enhanced_confidence
            })
            
            # Check for model drift
            self._detect_model_drift()
            
            return min(0.95, enhanced_confidence)
            
        except Exception as e:
            logger.error(f"Error enhancing signal with ML: {e}")
            return base_confidence
    
    def _get_ml_ensemble_prediction(self, features: Dict) -> Optional[Dict]:
        """Get prediction from ML ensemble."""
        if not self.ml_ensemble_models:
            return None
        
        # Prepare features for ML (Week 7)
        ml_features = self._prepare_ml_features(features)
        
        # Get predictions from all models
        predictions = []
        for model in self.ml_ensemble_models:
            try:
                pred = self._predict_with_model(model, ml_features)
                if pred:
                    predictions.append(pred)
            except Exception as e:
                logger.warning(f"Model prediction failed: {e}")
        
        if not predictions:
            return None
        
        # Ensemble: average predictions
        avg_confidence = sum(p['confidence'] for p in predictions) / len(predictions)
        buy_votes = sum(1 for p in predictions if p['direction'] == 'BUY')
        
        return {
            'direction': 'BUY' if buy_votes > len(predictions) / 2 else 'SELL',
            'confidence': avg_confidence,
            'ensemble_size': len(predictions),
            'agreement': buy_votes / len(predictions)
        }
    
    def _prepare_ml_features(self, raw_features: Dict) -> Dict:
        """
        Prepare and cache features for ML models (Week 7).
        
        Implements feature store with TTL caching.
        """
        # Check cache first
        feature_key = self._hash_features(raw_features)
        current_time = time.time()
        
        if feature_key in self.feature_cache:
            cached_entry = self.feature_cache[feature_key]
            if current_time - cached_entry['timestamp'] < self.feature_cache_ttl:
                self._cache_hits = getattr(self, '_cache_hits', 0) + 1
                return cached_entry['features']
        
        self._cache_misses = getattr(self, '_cache_misses', 0) + 1
        
        # Prepare features
        prepared_features = {
            'trap_strength': raw_features.get('liquidity_trap', 0),
            'support_resistance': raw_features.get('key_levels', 0),
            'volume_profile': raw_features.get('volume_intensity', 0),
            'order_flow_imbalance': raw_features.get('order_flow', 0),
            'volatility': raw_features.get('volatility', 0.02),
            'liquidity_score': raw_features.get('liquidity', 0.5),
            'timestamp': current_time
        }
        
        # Store in cache
        if len(self.feature_cache) >= self.feature_cache_max_size:
            # Remove oldest entry
            oldest_key = min(self.feature_cache.keys(), 
                           key=lambda k: self.feature_cache[k]['timestamp'])
            del self.feature_cache[oldest_key]
        
        self.feature_cache[feature_key] = {
            'features': prepared_features,
            'timestamp': current_time
        }
        
        return prepared_features
    
    def _hash_features(self, features: Dict) -> str:
        """Create hash key for feature caching."""
        key_str = '|'.join(str(features.get(k, 0)) for k in sorted(features.keys())[:5])
        return hashlib.sha256(key_str.encode()).hexdigest()[:16]
        return hashlib.sha256(key_str.encode()).hexdigest()[:16]
    def _predict_with_model(self, model: Any, features: Dict) -> Optional[Dict]:
        """Make prediction with a single model."""
        # Placeholder - in production, would call actual model
        trap_strength = features.get('trap_strength', 0.5)
        volume = features.get('volume_profile', 0.5)
        
        confidence = (trap_strength * 0.6 + volume * 0.4)
        direction = 'BUY' if trap_strength > 0.5 else 'SELL'  # Trap breakout
        
        return {
            'direction': direction,
            'confidence': confidence,
            'model_id': str(id(model))
        }
    
    def _detect_model_drift(self):
        """Detect model drift by comparing recent accuracy to baseline (Week 7)."""
        if len(self.ml_predictions) < 20:
            return
        
        recent_predictions = list(self.ml_predictions)[-50:]
        
        # Calculate recent accuracy (simplified)
        recent_confidences = [p['confidence'] for p in recent_predictions]
        self.current_accuracy = sum(recent_confidences) / len(recent_confidences)
        
        # Check for significant degradation
        accuracy_drop = self.baseline_accuracy - self.current_accuracy
        if accuracy_drop > self.drift_threshold:
            self.drift_detected = True
            logger.warning(
                f"âš ï¸ Model drift detected: accuracy dropped from "
                f"{self.baseline_accuracy:.2%} to {self.current_accuracy:.2%}"
            )
        else:
            self.drift_detected = False
    
    # ========================================================================
    # ML PARAMETER MANAGER (Week 7)
    # ========================================================================
    
    def update_ml_parameters(self, performance_metrics: Dict[str, float]) -> Dict[str, Any]:
        """
        Update ML parameters based on recent performance (Week 7).
        
        Dynamically adjusts ML confidence thresholds, weights, and other parameters
        based on model performance to optimize signal quality.
        """
        if not self.ml_parameter_manager['adaptive_enabled']:
            return self.ml_parameter_manager
        
        # Check if it's time to update
        if len(self.ml_predictions) < self.ml_parameter_manager['min_prediction_samples']:
            return self.ml_parameter_manager
        
        # Increment update count
        self.ml_parameter_update_count += 1
        
        # Only update at specified frequency
        if self.ml_parameter_update_count % self.ml_parameter_manager['parameter_update_frequency'] != 0:
            return self.ml_parameter_manager
        
        # Calculate performance metrics from recent predictions
        recent_predictions = list(self.ml_predictions)[-50:]
        if not recent_predictions:
            return self.ml_parameter_manager
        
        # Calculate prediction accuracy
        avg_confidence = sum(p['confidence'] for p in recent_predictions) / len(recent_predictions)
        
        # Adaptive adjustments
        learning_rate = self.ml_parameter_manager['learning_rate']
        momentum = self.ml_parameter_manager['momentum']
        
        # Adjust confidence threshold based on performance
        if avg_confidence < 0.5:
            # Low confidence - increase threshold to be more selective
            new_threshold = self.ml_parameter_manager['confidence_threshold'] * (1 + learning_rate)
            self.ml_parameter_manager['confidence_threshold'] = min(0.85, new_threshold)
        elif avg_confidence > 0.75:
            # High confidence - can be less strict
            new_threshold = self.ml_parameter_manager['confidence_threshold'] * (1 - learning_rate * 0.5)
            self.ml_parameter_manager['confidence_threshold'] = max(0.50, new_threshold)
        
        # Adjust ML weight based on drift detection
        if self.drift_detected:
            # Reduce ML weight if drift detected
            new_weight = self.ml_parameter_manager['ml_weight'] * (1 - learning_rate * 2)
            self.ml_parameter_manager['ml_weight'] = max(0.1, new_weight)
        else:
            # Can increase ML weight if no drift
            new_weight = self.ml_parameter_manager['ml_weight'] * (1 + learning_rate * 0.5)
            self.ml_parameter_manager['ml_weight'] = min(0.5, new_weight)
        
        # Record parameter update in history
        self.ml_parameter_history.append({
            'timestamp': time.time(),
            'parameters': self.ml_parameter_manager.copy(),
            'avg_confidence': avg_confidence,
            'drift_detected': self.drift_detected,
            'update_count': self.ml_parameter_update_count
        })
        
        logger.info(
            f"ðŸ“Š ML parameters updated: confidence_threshold={self.ml_parameter_manager['confidence_threshold']:.3f}, "
            f"ml_weight={self.ml_parameter_manager['ml_weight']:.3f}, "
            f"avg_confidence={avg_confidence:.3f}"
        )
        
        return self.ml_parameter_manager
    
    def get_ml_parameters(self) -> Dict[str, Any]:
        """
        Get current ML parameters (Week 7).
        
        Returns the current ML parameter configuration including confidence thresholds,
        weights, and adaptive settings.
        """
        return {
            'current_parameters': self.ml_parameter_manager.copy(),
            'update_count': self.ml_parameter_update_count,
            'parameter_history_size': len(self.ml_parameter_history),
            'adaptive_enabled': self.ml_parameter_manager['adaptive_enabled'],
            'last_update': self.ml_parameter_history[-1] if self.ml_parameter_history else None
        }
    
    def set_ml_parameter(self, parameter_name: str, value: Any) -> bool:
        """
        Set a specific ML parameter (Week 7).
        
        Allows manual override of ML parameters for testing or tuning.
        """
        if parameter_name in self.ml_parameter_manager:
            old_value = self.ml_parameter_manager[parameter_name]
            self.ml_parameter_manager[parameter_name] = value
            
            logger.info(
                f"ðŸ”§ ML parameter '{parameter_name}' updated: "
                f"{old_value} -> {value}"
            )
            
            # Record manual update
            self.ml_parameter_history.append({
                'timestamp': time.time(),
                'parameters': self.ml_parameter_manager.copy(),
                'manual_update': True,
                'parameter_changed': parameter_name,
                'old_value': old_value,
                'new_value': value
            })
            
            return True
        else:
            logger.warning(f"Unknown ML parameter: {parameter_name}")
            return False
    
    def reset_ml_parameters(self):
        """
        Reset ML parameters to defaults (Week 7).
        
        Useful for starting fresh or recovering from poor parameter states.
        """
        self.ml_parameter_manager = {
            'confidence_threshold': 0.57,
            'ml_weight': 0.3,
            'ensemble_agreement_threshold': 0.6,
            'min_prediction_samples': 10,
            'parameter_update_frequency': 50,
            'learning_rate': 0.05,
            'momentum': 0.9,
            'adaptive_enabled': True
        }
        self.ml_parameter_update_count = 0
        
        logger.info("ðŸ”„ ML parameters reset to defaults")
    
    def _calculate_cache_hit_rate(self) -> float:
        """Calculate feature cache hit rate."""
        if not hasattr(self, '_cache_hits'):
            self._cache_hits = 0
            self._cache_misses = 0
        
        total = self._cache_hits + self._cache_misses
        return self._cache_hits / total if total > 0 else 0.0
    
    # ========================================================================
    # EXECUTION QUALITY TRACKING (Week 8)
    # ========================================================================
    
    def record_fill(self, order_id: str, fill_data: Dict[str, Any]):
        """
        Record order fill with quality metrics (Week 8).
        
        Tracks slippage, fill time, partial fills, and execution quality.
        """
        with self._lock:
            if order_id not in self.pending_orders:
                logger.warning(f"Fill recorded for unknown order: {order_id}")
                return
            
            order = self.pending_orders[order_id]
            plan = order['plan']
            
            # Calculate fill metrics
            fill_time = time.time() - order['submitted_at']
            expected_price = plan['entry_price']
            actual_price = fill_data.get('fill_price', expected_price)
            filled_size = fill_data.get('filled_size', plan['size'])
            
            # Calculate slippage in basis points
            slippage_bps = abs(actual_price - expected_price) / expected_price * 10000
            slippage_cost = abs(actual_price - expected_price) * filled_size
            
            # Determine if partial fill
            is_partial = filled_size < plan['size']
            partial_fill_pct = filled_size / plan['size'] if plan['size'] > 0 else 0
            
            # Update execution metrics
            self.execution_metrics['total_fills'] += 1
            if is_partial:
                self.execution_metrics['partial_fills'] += 1
            else:
                self.execution_metrics['full_fills'] += 1
            
            self.execution_metrics['total_slippage_cost'] += slippage_cost
            
            # Record for statistics
            self.fill_times.append(fill_time)
            self.slippage_records.append(slippage_bps)
            self.latency_records.append(fill_time * 1000)  # Convert to ms
            
            # Update averages
            self.execution_metrics['average_fill_time'] = sum(self.fill_times) / len(self.fill_times)
            self.execution_metrics['average_slippage_bps'] = sum(self.slippage_records) / len(self.slippage_records)
            
            # Update percentile latencies
            if self.latency_records:
                sorted_latency = sorted(self.latency_records)
                n = len(sorted_latency)
                self.execution_metrics['latency_p50'] = sorted_latency[int(n * 0.50)]
                self.execution_metrics['latency_p95'] = sorted_latency[int(n * 0.95)]
                self.execution_metrics['latency_p99'] = sorted_latency[int(n * 0.99)]
            
            # Update fill rate
            total_orders = self.execution_metrics['total_fills']
            self.execution_metrics['fill_rate'] = (
                self.execution_metrics['full_fills'] / total_orders if total_orders > 0 else 0
            )
            
            # Log if significant slippage or partial fill
            if slippage_bps > 10:
                logger.warning(f"High slippage on fill: {slippage_bps:.1f} bps, cost: ${slippage_cost:.2f}")
            
            if is_partial and partial_fill_pct < 0.8:
                logger.warning(f"Significant partial fill: {partial_fill_pct:.1%} filled ({filled_size}/{plan['size']})")
            
            # Clean up pending order
            self.pending_orders.pop(order_id, None)
            
            logger.info(f"Fill recorded: {filled_size:.2f} @ ${actual_price:.2f}, slippage: {slippage_bps:.1f} bps, time: {fill_time*1000:.0f}ms")
    
    def _calculate_average_slippage(self) -> float:
        """Calculate average slippage in basis points."""
        if not self.slippage_records:
            return 0.0
        return sum(self.slippage_records) / len(self.slippage_records)
    
    def _calculate_fill_rate(self) -> float:
        """Calculate fill rate (full fills / total orders)."""
        total = self.execution_metrics['total_fills']
        if total == 0:
            return 0.0
        return self.execution_metrics['full_fills'] / total
    
    def _calculate_partial_fill_rate(self) -> float:
        """Calculate partial fill rate."""
        total = self.execution_metrics['total_fills']
        if total == 0:
            return 0.0
        return self.execution_metrics['partial_fills'] / total
    
    def _generate_order_id(self) -> str:
        """Generate unique order ID."""
        return f"TRAP_{int(time.time() * 1000)}_{secrets.token_hex(4)}"
    
    # ========================================================================
    # POSITION MANAGEMENT & VOLATILITY SCALING
    # ========================================================================
    
    def _convert_market_data_to_object(self, data: Dict, features: Dict) -> MarketData:
        """Convert dict to MarketData object."""
        try:
            instrument = data.get('symbol', 'UNKNOWN')
            timestamp = data.get('timestamp', datetime.now(timezone.utc))
            
            if isinstance(timestamp, (int, float)):
                timestamp = datetime.fromtimestamp(timestamp, tz=timezone.utc)
            elif isinstance(timestamp, str):
                timestamp = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            
            open_price = Decimal(str(data.get('open', 0.0)))
            high_price = Decimal(str(data.get('high', 0.0)))
            low_price = Decimal(str(data.get('low', 0.0)))
            close_price = Decimal(str(data.get('close', 0.0)))
            volume = int(data.get('volume', 0))
            bid = Decimal(str(data.get('bid', close_price)))
            ask = Decimal(str(data.get('ask', close_price)))
            bid_size = int(data.get('bid_size', 0))
            ask_size = int(data.get('ask_size', 0))
            
            return MarketData(
                instrument=instrument,
                timestamp=timestamp,
                open=open_price,
                high=high_price,
                low=low_price,
                close=close_price,
                volume=volume,
                bid=bid,
                ask=ask,
                bid_size=bid_size,
                ask_size=ask_size
            )
        except Exception as e:
            logger.error(f"Data conversion error: {e}")
            return MarketData(
                instrument='UNKNOWN',
                timestamp=datetime.now(timezone.utc),
                open=Decimal('0'), high=Decimal('0'), low=Decimal('0'), close=Decimal('0'), volume=0,
                bid=Decimal('0'), ask=Decimal('0'), bid_size=0, ask_size=0
            )
    
    def _update_volatility(self, data: MarketData):
        """Update realized volatility for position scaling."""
        try:
            self.volatility_window.append(float(data.close))
            
            if len(self.volatility_window) >= 2:
                prices = list(self.volatility_window)
                returns = [(prices[i] - prices[i-1]) / prices[i-1] 
                          for i in range(1, min(len(prices), 21))]
                
                if returns:
                    variance = sum(r**2 for r in returns) / len(returns)
                    daily_vol = math.sqrt(variance)
                    self.realized_volatility = daily_vol * math.sqrt(252)  # Annualize
        except Exception as e:
            logger.warning(f"Volatility update error: {e}")
    
    # ========================================================================
    # CRITICAL FIXES FROM ANALYSIS REPORT (W1.1-W1.4)
    # ========================================================================
    
    def _detect_gap_event(self, market_data: MarketData) -> Optional[Dict[str, Any]]:
        """W1.1 CRITICAL FIX: Detect overnight gaps that bypass traps (+8% signals)
        
        Gap types:
        - Up Gap: Open > Previous Close
        - Down Gap: Open < Previous Close
        - Gap Fill: Price returns to gap area
        
        Returns dict with gap analysis or None
        """
        try:
            # Need at least 2 bars of history
            if not hasattr(self, 'last_close_price') or self.last_close_price is None:
                self.last_close_price = market_data.close
                return None
            
            prev_close = self.last_close_price
            current_open = market_data.open
            
            # Calculate gap size
            gap_size = current_open - prev_close
            gap_pct = (gap_size / prev_close * 100) if prev_close > 0 else 0
            
            # Update last close for next iteration
            self.last_close_price = market_data.close
            
            # Classify gap
            if abs(float(gap_pct)) < 0.5:  # Less than 0.5% not significant
                return None
            
            gap_type = "UP_GAP" if gap_size > 0 else "DOWN_GAP"
            
            # Check if gap filled
            gap_filled = False
            if gap_type == "UP_GAP" and market_data.low <= prev_close:
                gap_filled = True
            elif gap_type == "DOWN_GAP" and market_data.high >= prev_close:
                gap_filled = True
            
            logger.debug(f"Gap event: {gap_type} of {gap_pct:.2f}%, filled={gap_filled}")
            
            return {
                "type": gap_type,
                "size": float(gap_size),
                "size_pct": float(gap_pct),
                "prev_close": float(prev_close),
                "current_open": float(current_open),
                "gap_filled": gap_filled,
                "significant": abs(float(gap_pct)) >= 0.5,
                "trap_potential": gap_filled  # Filled gap suggests trap
            }
            
        except Exception as e:
            logger.warning(f"Gap detection error: {e}")
            return None
    
    def _classify_breakout_validity(self, market_data: MarketData, 
                                     support: Optional[Decimal], 
                                     resistance: Optional[Decimal]) -> str:
        """W1.2 CRITICAL FIX: Classify if breakout is real or trap (-50% false signals)
        
        Analyzes:
        - Trend strength (using price action)
        - Volume confirmation
        - Order flow momentum
        
        Returns: "REAL_BREAKOUT", "LIQUIDITY_TRAP", or "UNCLEAR"
        """
        try:
            # Need price history for trend analysis
            if not hasattr(self.orchestrator.trap_detector, 'price_levels'):
                return "UNCLEAR"
            
            price_levels = list(self.orchestrator.trap_detector.price_levels)
            if len(price_levels) < 10:
                return "UNCLEAR"
            
            current_price = float(market_data.close)
            
            # Calculate trend strength (last 10 bars)
            recent_prices = price_levels[-10:]
            price_change = (float(recent_prices[-1]) - float(recent_prices[0])) / float(recent_prices[0])
            
            # Strong trend if >2% move in 10 bars
            strong_uptrend = price_change > 0.02
            strong_downtrend = price_change < -0.02
            
            # Analyze volume
            if hasattr(self.orchestrator.trap_detector.threshold_calculator, 'volume_history'):
                volumes = list(self.orchestrator.trap_detector.threshold_calculator.volume_history)
                if len(volumes) >= 10:
                    recent_vol = sum(volumes[-3:]) / 3
                    avg_vol = sum(volumes) / len(volumes)
                    high_volume = recent_vol > avg_vol * 1.5
                else:
                    high_volume = False
            else:
                high_volume = False
            
            # Classification logic
            if resistance and current_price > float(resistance):
                # Breakout above resistance
                if strong_uptrend and high_volume:
                    logger.debug(f"REAL BREAKOUT: strong uptrend + high volume")
                    return "REAL_BREAKOUT"
                elif not strong_uptrend and not high_volume:
                    logger.debug(f"LIQUIDITY TRAP: weak trend + low volume above resistance")
                    return "LIQUIDITY_TRAP"
            
            elif support and current_price < float(support):
                # Breakout below support
                if strong_downtrend and high_volume:
                    logger.debug(f"REAL BREAKOUT: strong downtrend + high volume")
                    return "REAL_BREAKOUT"
                elif not strong_downtrend and not high_volume:
                    logger.debug(f"LIQUIDITY TRAP: weak trend + low volume below support")
                    return "LIQUIDITY_TRAP"
            
            return "UNCLEAR"
            
        except Exception as e:
            logger.warning(f"Breakout classification error: {e}")
            return "UNCLEAR"
    
    def _detect_whipsaw_risk(self, price_level: Decimal) -> bool:
        """W1.3 CRITICAL FIX: Detect if area has multiple recent reversals (+10% Sharpe)
        
        Whipsaw = Multiple trap reversals in same price area
        High risk if >2 reversals in Â±2% range within 24 hours
        
        Returns True if whipsaw risk detected
        """
        try:
            # Initialize whipsaw tracking if not exists
            if not hasattr(self, 'reversal_history'):
                self.reversal_history = deque(maxlen=100)
            
            # Check for recent reversals near this price level
            price_float = float(price_level)
            tolerance = price_float * 0.02  # Â±2% range
            
            # Count reversals in range within last 24 hours
            now = datetime.now(timezone.utc)
            recent_reversals = []
            
            for reversal in self.reversal_history:
                # Check if within time window (24 hours)
                time_diff = (now - reversal['timestamp']).total_seconds()
                if time_diff > 86400:  # 24 hours in seconds
                    continue
                
                # Check if within price range
                rev_price = reversal['price']
                if abs(rev_price - price_float) <= tolerance:
                    recent_reversals.append(reversal)
            
            whipsaw_detected = len(recent_reversals) >= 2
            
            if whipsaw_detected:
                logger.warning(f"WHIPSAW RISK at {price_float:.2f}: {len(recent_reversals)} reversals in 24h")
            
            return whipsaw_detected
            
        except Exception as e:
            logger.warning(f"Whipsaw detection error: {e}")
            return False
    
    def _record_reversal(self, price: Decimal, trap_type: str):
        """Record a trap reversal for whipsaw tracking"""
        try:
            if not hasattr(self, 'reversal_history'):
                self.reversal_history = deque(maxlen=100)
            
            self.reversal_history.append({
                'price': float(price),
                'type': trap_type,
                'timestamp': datetime.now(timezone.utc)
            })
        except Exception as e:
            logger.warning(f"Reversal recording error: {e}")
    
    def _check_regime_fitness(self, mqscore_components: Optional[Dict]) -> float:
        """W1.4 CRITICAL FIX: Check market regime fitness for trap trading (+12% consistency)
        
        Liquidity traps work best in:
        - Ranging markets (trend_strength: 0.2-0.4)
        - Moderate volatility (volatility: 0.3-0.6)
        
        Returns fitness score 0.0-1.0 (1.0 = ideal conditions)
        """
        try:
            if not mqscore_components:
                return 0.5  # Neutral if no MQScore
            
            trend_strength = mqscore_components.get('trend_strength', 0.5)
            volatility = mqscore_components.get('volatility', 0.5)
            
            # Ideal ranges for trap trading
            ideal_trend_min, ideal_trend_max = 0.2, 0.4  # Ranging market
            ideal_vol_min, ideal_vol_max = 0.3, 0.6      # Moderate volatility
            
            # Calculate trend fitness
            if ideal_trend_min <= trend_strength <= ideal_trend_max:
                trend_fitness = 1.0
            elif trend_strength < ideal_trend_min:
                # Too low trending (very range-bound)
                trend_fitness = trend_strength / ideal_trend_min
            else:
                # Too strong trending (bad for traps)
                trend_fitness = max(0.0, 1.0 - (trend_strength - ideal_trend_max) / 0.6)
            
            # Calculate volatility fitness
            if ideal_vol_min <= volatility <= ideal_vol_max:
                vol_fitness = 1.0
            elif volatility < ideal_vol_min:
                # Too low volatility
                vol_fitness = volatility / ideal_vol_min
            else:
                # Too high volatility
                vol_fitness = max(0.0, 1.0 - (volatility - ideal_vol_max) / 0.4)
            
            # Combined fitness (weighted)
            regime_fitness = 0.6 * trend_fitness + 0.4 * vol_fitness
            
            logger.debug(f"Regime fitness: {regime_fitness:.2f} (trend={trend_strength:.2f}, vol={volatility:.2f})")
            
            return regime_fitness
            
        except Exception as e:
            logger.warning(f"Regime fitness error: {e}")
            return 0.5
    
    # ========================================================================
    # POSITION MANAGEMENT & VOLATILITY SCALING
    # ========================================================================
    
    def _calculate_position_size_with_scaling(self, confidence: float, current_price: float) -> float:
        """
        Calculate position size with volatility scaling.
        
        Implements dynamic position sizing based on realized volatility.
        """
        # Base position size from signal confidence
        base_size_pct = 0.10 * confidence  # Up to 10% of equity
        base_size_dollars = self.current_equity * base_size_pct
        
        # Volatility scaling: reduce size in high volatility
        target_vol = 0.20  # Target 20% annualized volatility
        vol_scalar = min(2.0, target_vol / max(self.realized_volatility, 0.05))
        
        # Apply scaling
        scaled_size_dollars = base_size_dollars * vol_scalar
        
        # Convert to position size
        position_size = scaled_size_dollars / current_price if current_price > 0 else 0
        
        # Check concentration limit
        max_position_size = (self.current_equity * self.max_single_position_pct) / current_price
        position_size = min(position_size, max_position_size)
        
        logger.debug(
            f"Position size: base=${base_size_dollars:.0f}, vol_scalar={vol_scalar:.2f}, "
            f"final={position_size:.2f} units (vol={self.realized_volatility:.1%})"
        )
        
        return position_size
    
    def calculate_position_entry_logic(self, confidence: float, entry_price: float) -> Dict[str, Any]:
        """
        Calculate position entry logic with scale-in and pyramiding.
        
        Required component - implements sophisticated entry strategy.
        """
        # Scale-in levels based on confidence
        if confidence >= 0.85:
            # High confidence: aggressive entry
            entry_levels = [
                {'price': entry_price, 'size_pct': 0.50},
                {'price': entry_price * 0.999, 'size_pct': 0.30},
                {'price': entry_price * 0.998, 'size_pct': 0.20},
            ]
        elif confidence >= 0.70:
            # Medium confidence: graduated entry
            entry_levels = [
                {'price': entry_price, 'size_pct': 0.40},
                {'price': entry_price * 0.998, 'size_pct': 0.35},
                {'price': entry_price * 0.996, 'size_pct': 0.25},
            ]
        else:
            # Lower confidence: conservative entry
            entry_levels = [
                {'price': entry_price, 'size_pct': 0.30},
                {'price': entry_price * 0.997, 'size_pct': 0.40},
                {'price': entry_price * 0.994, 'size_pct': 0.30},
            ]
        
        # Pyramiding rules
        pyramiding_enabled = confidence >= 0.75
        max_pyramid_levels = 2 if confidence >= 0.85 else 1
        
        return {
            'entry_type': 'SCALE_IN',
            'entry_levels': entry_levels,
            'pyramiding_enabled': pyramiding_enabled,
            'max_pyramid_levels': max_pyramid_levels,
            'pyramid_trigger': 'PROFIT_THRESHOLD',
            'pyramid_profit_threshold': 0.02,
        }
    
    def _calculate_entry_exit_logic(self, signal_info: Any, data: MarketData, confidence: float) -> Dict[str, Any]:
        """Calculate entry and exit logic for the signal."""
        entry_price = float(signal_info.price)
        entry = self.calculate_position_entry_logic(confidence, entry_price)
        exit_logic = self.calculate_position_exit_logic(signal_info, data, confidence)
        
        return {
            'entry': entry,
            'stop_loss': exit_logic['stop_loss'],
            'take_profit': exit_logic['take_profit'],
            'trailing_stop': exit_logic['trailing_stop'],
            'exit_triggers': exit_logic['exit_triggers']
        }
    
    def calculate_position_exit_logic(self, signal_info: Any, market_data: MarketData, confidence: float) -> Dict[str, Any]:
        """
        Calculate position exit logic with multiple triggers and trailing stops.
        
        Required component - implements comprehensive exit strategy.
        """
        entry_price = float(signal_info.price)
        
        # Calculate ATR-based stops
        atr_proxy = entry_price * self.realized_volatility / math.sqrt(252)
        
        # Stop loss: 2x ATR or 2%, whichever is tighter
        stop_distance = min(atr_proxy * 2, entry_price * 0.02)
        
        if signal_info.signal_type == SignalType.LONG:
            stop_loss = entry_price - stop_distance
            take_profit = entry_price + (stop_distance * 3)
        else:
            stop_loss = entry_price + stop_distance
            take_profit = entry_price - (stop_distance * 3)
        
        # Trailing stop configuration
        trailing_stop = {
            'enabled': True,
            'activation_profit_pct': 0.015,
            'trail_distance_pct': 0.01,
            'trail_step_pct': 0.005,
        }
        
        # Multiple exit triggers
        exit_triggers = [
            {
                'type': 'TIME_BASED',
                'max_hold_periods': 20,
                'description': 'Time-based exit for stale positions'
            },
            {
                'type': 'PROFIT_TARGET',
                'target_pct': 0.04,
                'partial_exit_pct': 0.50,
                'description': 'Partial profit taking at target'
            },
            {
                'type': 'VOLUME_DECLINE',
                'volume_threshold_pct': 0.40,
                'description': 'Exit on volume exhaustion'
            },
            {
                'type': 'TRAP_REVERSAL',
                'reversal_threshold': 0.70,
                'description': 'Exit on trap pattern reversal'
            },
            {
                'type': 'ADVERSE_MOVE',
                'adverse_move_pct': 0.015,
                'recovery_periods': 3,
                'description': 'Exit on adverse move without recovery'
            },
            {
                'type': 'VOLATILITY_SPIKE',
                'volatility_multiplier': 2.5,
                'description': 'Exit on extreme volatility'
            }
        ]
        
        return {
            'stop_loss': stop_loss,
            'take_profit': take_profit,
            'trailing_stop': trailing_stop,
            'exit_triggers': exit_triggers,
            'atr_value': atr_proxy,
            'risk_amount': stop_distance,
            'reward_amount': abs(take_profit - entry_price),
            'risk_reward_ratio': abs(take_profit - entry_price) / stop_distance if stop_distance > 0 else 0
        }
    
    def calculate_leverage_ratio(self) -> Dict[str, Any]:
        """
        Calculate current leverage ratio and margin requirements.
        
        Required component - implements leverage management.
        """
        with self._position_lock:
            total_position_value = sum(
                pos.get('size', 0) * pos.get('entry_price', 0)
                for pos in self.current_positions.values()
            )
            
            # Calculate leverage
            if self.current_equity > 0:
                current_leverage = total_position_value / self.current_equity
            else:
                current_leverage = 0.0
            
            # Calculate margin requirements (assume 33% margin for 3x leverage)
            required_margin = total_position_value / self.max_leverage
            available_margin = self.current_equity - required_margin
            margin_utilization = required_margin / self.current_equity if self.current_equity > 0 else 0
            
            # Calculate buying power
            buying_power = self.current_equity * self.max_leverage - total_position_value
            
            # Check if over-leveraged
            over_leveraged = current_leverage > self.max_leverage
            
            return {
                'current_leverage': current_leverage,
                'max_leverage': self.max_leverage,
                'total_position_value': total_position_value,
                'current_equity': self.current_equity,
                'required_margin': required_margin,
                'available_margin': available_margin,
                'margin_utilization_pct': margin_utilization,
                'buying_power': buying_power,
                'over_leveraged': over_leveraged,
                'leverage_headroom': self.max_leverage - current_leverage,
            }
    
    def _calculate_leverage_metrics(self) -> Dict[str, Any]:
        """Get leverage metrics for reporting."""
        return self.calculate_leverage_ratio()
    
    def update_position(self, symbol: str, pnl: float, closed: bool = False):
        """Update position state and performance metrics."""
        with self._lock:
            # Update equity and P&L
            self.current_equity += pnl
            self.daily_pnl += pnl
            
            # Update peak equity if new high
            if self.current_equity > self.peak_equity:
                self.peak_equity = self.current_equity
            
            # Calculate return for risk metrics
            if self.current_equity > 0:
                period_return = pnl / (self.current_equity - pnl)
                self.returns_history.append(period_return)
            
            # Update consecutive losses tracking
            if pnl < 0:
                self.consecutive_losses += 1
            else:
                self.consecutive_losses = 0
            
            # Record trade in metrics
            self.metrics.record_trade(pnl, self.current_equity)
            
            # Update position concentration
            if not closed and symbol in self.current_positions:
                position_value = (
                    self.current_positions[symbol].get('size', 0) *
                    self.current_positions[symbol].get('current_price', 0)
                )
                self.position_concentrations[symbol] = (
                    position_value / self.current_equity if self.current_equity > 0 else 0
                )
            elif closed and symbol in self.position_concentrations:
                del self.position_concentrations[symbol]
            
            # Log significant events
            if pnl < -1000:
                logger.warning(f"Large loss: ${pnl:.2f} on {symbol}")
            elif pnl > 1000:
                logger.info(f"Large win: ${pnl:.2f} on {symbol}")
    
    def reset_daily_metrics(self):
        """Reset daily metrics (call at start of each trading day)."""
        with self._lock:
            self.daily_pnl = 0.0
            self.consecutive_losses = 0
            logger.info("Daily metrics reset for new trading day")
    
    def reset_kill_switch(self):
        """Manually reset kill switch (use with caution)."""
        with self._lock:
            self.kill_switch_active = False
            self.kill_switch_reason = None
            self.consecutive_losses = 0
            logger.info("Kill switch manually reset")


# =====================================================================
# NEXUS AI INTEGRATION ADAPTER ASSIGNMENTS
# =====================================================================
# Create the main strategy instance for NEXUS AI integration
# This allows the strategy to be imported and used directly
TradingStrategy = LiquidityTrapsNexusAdapterV2
MainStrategy = LiquidityTrapsNexusAdapterV2
LiquidityTrapsStrategy = LiquidityTrapsNexusAdapterV2


# =====================================================================
# PERFORMANCE METRICS CLASS V2
# =====================================================================

@dataclass
class PerformanceMetricsV2:
    """Enhanced performance metrics tracking."""
    total_trades: int = 0
    winning_trades: int = 0
    losing_trades: int = 0
    total_pnl: float = 0.0
    max_consecutive_wins: int = 0
    max_consecutive_losses: int = 0
    current_consecutive_wins: int = 0
    current_consecutive_losses: int = 0
    largest_win: float = 0.0
    largest_loss: float = 0.0
    average_win: float = 0.0
    average_loss: float = 0.0
    profit_factor: float = 0.0
    sharpe_ratio: float = 0.0
    max_drawdown: float = 0.0
    current_drawdown: float = 0.0
    peak_equity: float = 0.0
    daily_returns: List[float] = field(default_factory=list)
    error_count: int = 0
    validation_failures: int = 0

    @property
    def win_rate(self) -> float:
        if self.total_trades == 0:
            return 0.0
        return self.winning_trades / self.total_trades

    @property
    def average_return(self) -> float:
        if self.total_trades == 0:
            return 0.0
        return self.total_pnl / self.total_trades

    def record_trade(self, pnl: float, equity: float = None):
        """Record a trade with enhanced metrics tracking."""
        self.total_trades += 1
        self.total_pnl += pnl

        if pnl > 0:
            self.winning_trades += 1
            self.current_consecutive_wins += 1
            self.current_consecutive_losses = 0
            self.max_consecutive_wins = max(self.max_consecutive_wins, self.current_consecutive_wins)
            self.largest_win = max(self.largest_win, pnl)
        else:
            self.losing_trades += 1
            self.current_consecutive_losses += 1
            self.current_consecutive_wins = 0
            self.max_consecutive_losses = max(self.max_consecutive_losses, self.current_consecutive_losses)
            self.largest_loss = min(self.largest_loss, pnl)

        if self.winning_trades > 0:
            self.average_win = self.total_pnl / self.winning_trades if self.winning_trades > 0 else 0
        if self.losing_trades > 0:
            self.average_loss = self.total_pnl / self.losing_trades if self.losing_trades > 0 else 0

        if self.average_loss != 0:
            self.profit_factor = abs(self.average_win / self.average_loss)

        if equity is not None:
            if equity > self.peak_equity:
                self.peak_equity = equity
                self.current_drawdown = 0.0
            else:
                self.current_drawdown = (self.peak_equity - equity) / self.peak_equity
                self.max_drawdown = max(self.max_drawdown, self.current_drawdown)


# =====================================================================
# ADAPTER REGISTRATION & HELPER FUNCTIONS
# =====================================================================

def create_liquidity_traps_adapter_v2(config: Optional[Dict[str, Any]] = None) -> LiquidityTrapsNexusAdapterV2:
    """
    Factory function to create properly configured adapter V2.
    
    Usage:
        adapter = create_liquidity_traps_adapter_v2({
            'initial_capital': 100000,
            'max_daily_loss': 2000,
            'max_leverage': 3.0
        })
    """
    return LiquidityTrapsNexusAdapterV2(config=config)


# Create aliases for compatibility with different naming conventions
LiquidityTrapStrategy = LiquidityTrapsNexusAdapterV2
EnhancedLiquidityTrapStrategy = LiquidityTrapsNexusAdapterV2
LiquidityTrapsStrategy = LiquidityTrapsNexusAdapterV2

# Export adapter class for NEXUS AI pipeline
__all__ = [
    'LiquidityTrapsNexusAdapterV2',
    'LiquidityTrapStrategy',
    'EnhancedLiquidityTrapStrategy',
    'LiquidityTrapsStrategy',
    'create_liquidity_traps_adapter_v2',
]

logger.info("LiquidityTrapsNexusAdapterV2 module loaded successfully")

# ============================================================================
# PHASE 1: FOUNDATION INTEGRATION - STRATEGY REGISTRATION & VALIDATION
# ============================================================================
# Integrated directly into liquidity_traps.py (no separate phase files)
# All Phase 1-5 development happens within this single codebase

from enum import Enum
from dataclasses import dataclass
from typing import Optional, Dict, Any


class StrategyRegistrationCategory(Enum):
    """Strategy categories for nexus_ai.py weight optimization"""
    VOLATILITY_BREAKOUT = "VOLATILITY_BREAKOUT"
    MARKET_MAKING = "Market Making"
    MEAN_REVERSION = "Mean Reversion"
    ORDER_FLOW = "Order Flow"
    TREND_FOLLOWING = "Trend Following"
    BREAKOUT = "Breakout"
    MOMENTUM = "Momentum"


@dataclass
class StrategyRegistrationConfig:
    """Configuration for Phase 1 strategy registration"""
    strategy_name: str = "liquidity_traps_v2"
    category: StrategyRegistrationCategory = StrategyRegistrationCategory.VOLATILITY_BREAKOUT
    initial_weight: float = 0.14  # 14% initial allocation
    min_weight: float = 0.05
    max_weight: float = 0.25
    performance_tracking_enabled: bool = True
    regime_adaptation_enabled: bool = True
    ml_integration_enabled: bool = False  # Phase 6


class Phase1StrategyRegistration:
    """
    PHASE 1: FOUNDATION INTEGRATION
    Handles registration of LiquidityTrapsNexusAdapterV2 with nexus_ai.py
    
    Responsibilities:
    - Register in EnhancedStrategyManager._strategies list
    - Assign category weight (VOLATILITY_BREAKOUT: 14%)
    - Implement performance metrics tracking
    - Setup signal format validation
    """
    
    def __init__(self, config: Optional[StrategyRegistrationConfig] = None):
        self.config = config or StrategyRegistrationConfig()
        self.registration_status = "PENDING"
        self.validation_results = {}
        self.timestamp = datetime.now().isoformat()
        logger.debug(f"Phase 1 StrategyRegistration initialized at {self.timestamp}")
    
    def validate_adapter_interface(self, adapter_class) -> Dict[str, bool]:
        """Validate adapter implements required interface"""
        validations = {
            "has_execute": hasattr(adapter_class, 'execute') and callable(getattr(adapter_class, 'execute')),
            "has_get_category": hasattr(adapter_class, 'get_category') and callable(getattr(adapter_class, 'get_category')),
            "has_get_performance_metrics": hasattr(adapter_class, 'get_performance_metrics') and callable(getattr(adapter_class, 'get_performance_metrics')),
        }
        
        all_valid = all(validations.values())
        if all_valid:
            logger.info("âœ“ Adapter interface validation PASSED")
        else:
            logger.error(f"âœ— Adapter interface validation FAILED: {validations}")
        
        self.validation_results['adapter_interface'] = validations
        return validations
    
    def validate_signal_format(self, sample_signal: Dict) -> Dict[str, bool]:
        """Validate signal output format for nexus_ai.py compatibility"""
        required_fields = ['signal', 'confidence', 'metadata']
        validations = {}
        
        for field in required_fields:
            present = field in sample_signal
            validations[f"has_{field}"] = present
            
            if field == 'signal' and present:
                validations['signal_in_range'] = -1.0 <= sample_signal[field] <= 1.0
            
            if field == 'confidence' and present:
                validations['confidence_in_range'] = 0.0 <= sample_signal[field] <= 1.0
            
            if field == 'metadata' and present:
                metadata = sample_signal[field]
                validations['metadata_has_action'] = 'action' in metadata
                validations['metadata_has_stop_loss'] = 'stop_loss' in metadata
                validations['metadata_has_take_profit'] = 'take_profit' in metadata
        
        all_valid = all(validations.values())
        status = "âœ“ PASSED" if all_valid else "âœ— FAILED"
        logger.debug(f"{status}: Signal format validation: {validations}")
        
        self.validation_results['signal_format'] = validations
        return validations
    
    def setup_category_weights(self) -> Dict[str, float]:
        """Configure category weights for signal blending"""
        weights = {
            "MARKET_MAKING": 0.25,      # 25% (reduced from 28%)
            "MEAN_REVERSION": 0.15,     # 15% (reduced from 17%)
            "ORDER_FLOW": 0.13,         # 13% (reduced from 15%)
            "TREND_FOLLOWING": 0.13,    # 13% (reduced from 15%)
            "BREAKOUT": 0.12,           # 12% (reduced from 13%)
            "MOMENTUM": 0.10,           # 10% (reduced from 12%)
            "VOLATILITY_BREAKOUT": 0.12 # 12% (NEW - liquidity_traps)
        }
        
        # Verify normalization
        total = sum(weights.values())
        assert abs(total - 1.0) < 0.01, f"Weights don't sum to 1.0: {total}"
        
        logger.debug(f"Category weights configured: {weights}")
        self.validation_results['category_weights'] = weights
        return weights
    
    def register_in_strategy_manager(self, adapter_instance) -> bool:
        """Register adapter in nexus_ai.py EnhancedStrategyManager"""
        try:
            # Validation step
            interface_valid = self.validate_adapter_interface(adapter_instance.__class__)
            if not all(interface_valid.values()):
                logger.error("Cannot register: adapter interface invalid")
                return False
            
            # Registration parameters
            registration_data = {
                "strategy_name": self.config.strategy_name,
                "category": self.config.category.value,
                "initial_weight": self.config.initial_weight,
                "adapter_instance": adapter_instance,
                "performance_tracking": self.config.performance_tracking_enabled,
                "regime_adaptation": self.config.regime_adaptation_enabled,
            }
            
            logger.info(f"âœ“ Strategy registration ready: {registration_data}")
            self.registration_status = "REGISTERED"
            self.validation_results['registration'] = registration_data
            
            return True
            
        except Exception as e:
            logger.error(f"Registration error: {e}")
            return False


class Phase1ValidationSuite:
    """Phase 1 unit tests for strategy registration and validation"""
    
    def __init__(self):
        self.registration = Phase1StrategyRegistration()
        self.test_results = {}
        self.passed_count = 0
        self.failed_count = 0
    
    def test_registration_config(self) -> bool:
        """Test registration configuration"""
        try:
            config = StrategyRegistrationConfig()
            
            assert config.strategy_name == "liquidity_traps_v2"
            assert config.category == StrategyRegistrationCategory.VOLATILITY_BREAKOUT
            assert config.initial_weight == 0.14
            assert config.min_weight == 0.05
            assert config.max_weight == 0.25
            assert config.performance_tracking_enabled == True
            assert config.regime_adaptation_enabled == True
            assert config.ml_integration_enabled == False
            
            logger.debug("Registration config test PASSED")
            self.test_results['test_registration_config'] = True
            self.passed_count += 1
            return True
        
        except AssertionError as e:
            logger.error(f"âœ— Registration config test FAILED: {e}")
            self.test_results['test_registration_config'] = False
            self.failed_count += 1
            return False
    
    def test_signal_format_validation(self) -> bool:
        """Test signal format validation"""
        try:
            sample_signal = {
                'signal': 0.75,
                'confidence': 0.85,
                'metadata': {
                    'action': 'BUY',
                    'stop_loss': 100.0,
                    'take_profit': 110.0
                }
            }
            
            results = self.registration.validate_signal_format(sample_signal)
            all_valid = all(results.values())
            
            assert all_valid, f"Signal format validation failed: {results}"
            logger.debug("Signal format test PASSED")
            self.test_results['test_signal_format_validation'] = True
            self.passed_count += 1
            return True
        
        except AssertionError as e:
            logger.error(f"âœ— Signal format test FAILED: {e}")
            self.test_results['test_signal_format_validation'] = False
            self.failed_count += 1
            return False
    
    def test_category_weights(self) -> bool:
        """Test category weight configuration"""
        try:
            weights = self.registration.setup_category_weights()
            
            # Verify normalization
            total = sum(weights.values())
            assert abs(total - 1.0) < 0.01, f"Weights don't sum to 1.0: {total}"
            
            # Verify liquidity_traps weight
            assert weights["VOLATILITY_BREAKOUT"] == 0.12, "Liquidity traps weight incorrect"
            
            # Verify all weights are positive
            for category, weight in weights.items():
                assert weight > 0, f"Non-positive weight for {category}: {weight}"
            
            logger.debug("Category weights test PASSED")
            self.test_results['test_category_weights'] = True
            self.passed_count += 1
            return True
        
        except AssertionError as e:
            logger.error(f"âœ— Category weights test FAILED: {e}")
            self.test_results['test_category_weights'] = False
            self.failed_count += 1
            return False
    
    def run_all_tests(self) -> bool:
        """Run all Phase 1 validation tests"""
        logger.debug("PHASE 1: FOUNDATION INTEGRATION - RUNNING VALIDATION SUITE")
        
        self.test_registration_config()
        self.test_signal_format_validation()
        self.test_category_weights()
        
        logger.debug(f"PHASE 1 RESULTS: {self.passed_count} PASSED, {self.failed_count} FAILED")
        
        return self.failed_count == 0


# Phase 1 Auto-Initialization
def initialize_phase1():
    """Initialize Phase 1 validation suite"""
    logger.debug("PHASE 1: FOUNDATION INTEGRATION - INITIALIZATION")
    
    suite = Phase1ValidationSuite()
    all_passed = suite.run_all_tests()
    
    if all_passed:
        logger.debug("PHASE 1 VALIDATION COMPLETE - ALL TESTS PASSED")
        return True
    else:
        logger.error("\nâŒ PHASE 1 VALIDATION FAILED - REVIEW ERRORS ABOVE\n")
        return False


# Main execution moved to end of file after all function definitions

# ============================================================================
# PHASE 2: MQSCORE REGIME FILTERING - MARKET REGIME DETECTION
# ============================================================================

class Phase2RegimeFilter:
    """
    PHASE 2: MQSCORE REGIME FILTERING
    Filters liquidity traps based on market regime from MQSCORE
    
    Optimal regime for liquidity traps:
    - Trend Strength: 0.2-0.4 (ranging market, not trending)
    - Volatility: 0.3-0.6 (moderate, not extreme)
    """
    
    def __init__(self, ideal_trend: float = 0.3, ideal_volatility: float = 0.45):
        self.ideal_trend = ideal_trend
        self.ideal_volatility = ideal_volatility
        self.regime_scores = {}
        logger.debug("Phase 2 RegimeFilter initialized")
    
    def calculate_regime_fitness(self, trend_strength: float, volatility: float) -> float:
        """Calculate how well current regime suits liquidity traps"""
        # Gaussian fitness centered at ideal values
        trend_distance = abs(trend_strength - self.ideal_trend) / 0.7
        vol_distance = abs(volatility - self.ideal_volatility) / 0.45
        
        # Gaussian fitness function
        fitness = np.exp(-0.5 * (trend_distance**2 + vol_distance**2))
        
        return max(0.3, min(1.0, fitness))  # Clamp 0.3-1.0
    
    def adjust_signal_confidence(self, base_confidence: float, 
                                trend_strength: float, volatility: float) -> float:
        """Adjust signal confidence based on regime fitness"""
        regime_fitness = self.calculate_regime_fitness(trend_strength, volatility)
        adjusted = base_confidence * regime_fitness
        
        return max(0.0, min(0.95, adjusted))


# ============================================================================
# PHASE 3: DELTA DIVERGENCE INTEGRATION - PRE-TRAP WARNING SYSTEM
# ============================================================================

class Phase3DeltaDivergencePredictor:
    """
    PHASE 3: DELTA DIVERGENCE INTEGRATION
    Identifies divergence between price and cumulative delta
    
    Detects:
    - Bearish divergence: Higher price, lower delta (short signal)
    - Bullish divergence: Lower price, higher delta (long signal)
    """
    
    def __init__(self, lookback_period: int = 50):
        self.lookback_period = lookback_period
        self.price_highs = deque(maxlen=lookback_period)
        self.price_lows = deque(maxlen=lookback_period)
        self.cumulative_delta = deque(maxlen=lookback_period)
        logger.debug("Phase 3 DeltaDivergencePredictor initialized")
    
    def detect_divergence(self, high: float, low: float, delta: float) -> tuple:
        """Detect price-delta divergence"""
        self.price_highs.append(high)
        self.price_lows.append(low)
        self.cumulative_delta.append(delta)
        
        if len(self.price_highs) < 3:
            return None, 0.0
        
        # Get recent extremes
        recent_highs = list(self.price_highs)[-5:]
        recent_lows = list(self.price_lows)[-5:]
        recent_deltas = list(self.cumulative_delta)[-5:]
        
        current_high = recent_highs[-1]
        current_low = recent_lows[-1]
        current_delta = recent_deltas[-1]
        
        # Check for bearish divergence (HH Price, LH Delta)
        if len(recent_highs) >= 2 and current_high > max(recent_highs[:-1]) and current_delta < max(recent_deltas[:-1]):
            divergence_strength = min(0.1, abs(current_high - max(recent_highs[:-1])) / current_high) if current_high > 0 else 0.05
            return 'BEARISH', min(0.25, divergence_strength * 2.5)
        
        # Check for bullish divergence (LL Price, HL Delta)
        if len(recent_lows) >= 2 and current_low < min(recent_lows[:-1]) and current_delta > min(recent_deltas[:-1]):
            divergence_strength = min(0.1, abs(min(recent_lows[:-1]) - current_low) / min(recent_lows[:-1])) if min(recent_lows[:-1]) > 0 else 0.05
            return 'BULLISH', min(0.25, divergence_strength * 2.5)
        
        return None, 0.0


# ============================================================================
# PHASE 4: HVN REFINEMENT - HIGH VOLUME NODE ANALYSIS
# ============================================================================

class Phase4HVNRefinedLevelFinder:
    """
    PHASE 4: HVN REFINEMENT
    Identifies major High Volume Nodes (top 10% of volume)
    Only trades traps at significant HVN levels
    """
    
    def __init__(self, hvn_percentile: float = 0.10, lookback_bars: int = 1000):
        self.hvn_percentile = hvn_percentile
        self.lookback_bars = lookback_bars
        self.volume_profile = {}
        self.major_hvns = []
        logger.debug("Phase 4 HVNRefinedLevelFinder initialized")
    
    def identify_major_hvns(self) -> List[float]:
        """Identify top 10% volume levels as major HVNs"""
        if not self.volume_profile:
            return []
        
        # Sort by volume
        sorted_levels = sorted(
            self.volume_profile.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # Get top 10%
        n_major = max(1, int(len(sorted_levels) * self.hvn_percentile))
        major_levels = [level for level, _ in sorted_levels[:n_major]]
        
        return sorted(major_levels)
    
    def filter_support_resistance_by_hvn(self, support: float, resistance: float) -> tuple:
        """Only return S/R levels if they are major HVNs"""
        major_hvns = self.identify_major_hvns()
        
        valid_support = support if support in major_hvns else None
        valid_resistance = resistance if resistance in major_hvns else None
        
        return valid_support, valid_resistance


# ============================================================================
# PHASE 5: MICROSTRUCTURE ENHANCEMENT - ADVANCED ORDER FLOW ANALYSIS
# ============================================================================

class Phase5AdvancedMicrostructureAnalyzer:
    """
    PHASE 5: MICROSTRUCTURE ENHANCEMENT
    Advanced order flow analysis:
    - Order flow momentum
    - Information ratio
    - Informed trading detection
    """
    
    def __init__(self):
        self.order_flow_momentum = deque(maxlen=20)
        self.information_ratios = deque(maxlen=100)
        self.flow_changes = deque(maxlen=10)
        logger.debug("Phase 5 AdvancedMicrostructureAnalyzer initialized")
    
    def calculate_order_flow_momentum(self, imbalances: deque) -> float:
        """Calculate momentum of order flow direction"""
        if len(imbalances) < 10:
            return 0.0
        
        recent = list(imbalances)[-10:]
        momentum = recent[-1] - recent[0]
        
        self.order_flow_momentum.append(momentum)
        return momentum
    
    def calculate_information_ratio(self, flow_volatility: float, price_volatility: float) -> float:
        """How much of price volatility is explained by order flow"""
        if price_volatility == 0:
            return 0.0
        
        info_ratio = flow_volatility / price_volatility
        self.information_ratios.append(info_ratio)
        
        return info_ratio
    
    def detect_informed_trading(self, flow_momentum: float, info_ratio: float) -> bool:
        """Detect informed trading patterns"""
        return abs(flow_momentum) > 0.5 and info_ratio > 1.5


# ============================================================================
# PHASES 2-5 INTEGRATED VALIDATION SUITE
# ============================================================================

class PhasesIntegratedValidation:
    """Integration test suite for all Phases 2-5"""
    
    def __init__(self):
        self.phase2 = Phase2RegimeFilter()
        self.phase3 = Phase3DeltaDivergencePredictor()
        self.phase4 = Phase4HVNRefinedLevelFinder()
        self.phase5 = Phase5AdvancedMicrostructureAnalyzer()
        self.results = {}
        logger.debug("PhasesIntegratedValidation initialized")
    
    def test_phase2_regime_filter(self) -> bool:
        """Test MQSCORE regime filtering"""
        try:
            # Test ideal regime
            fitness_ideal = self.phase2.calculate_regime_fitness(0.3, 0.45)
            assert fitness_ideal > 0.9, f"Ideal regime fitness too low: {fitness_ideal}"
            
            # Test poor regime
            fitness_poor = self.phase2.calculate_regime_fitness(0.8, 0.9)
            assert fitness_poor < 0.5, f"Poor regime fitness too high: {fitness_poor}"
            
            # Test confidence adjustment
            adjusted = self.phase2.adjust_signal_confidence(0.8, 0.3, 0.45)
            assert 0.7 < adjusted < 0.95, f"Confidence adjustment failed: {adjusted}"
            
            logger.debug("Phase 2 regime filter test PASSED")
            self.results['phase2'] = True
            return True
        
        except AssertionError as e:
            logger.error(f"âœ— Phase 2 test FAILED: {e}")
            self.results['phase2'] = False
            return False
    
    def test_phase3_delta_divergence(self) -> bool:
        """Test delta divergence detection"""
        try:
            # Simulate bearish divergence
            self.phase3.detect_divergence(110.0, 105.0, -100.0)
            self.phase3.detect_divergence(111.0, 106.0, -95.0)  # HH Price, LH Delta
            
            div_type, strength = self.phase3.detect_divergence(112.0, 107.0, -105.0)
            assert div_type == 'BEARISH', f"Divergence detection failed: {div_type}"
            assert 0 <= strength <= 0.25, f"Divergence strength invalid: {strength}"
            
            logger.debug("Phase 3 delta divergence test PASSED")
            self.results['phase3'] = True
            return True
        
        except AssertionError as e:
            logger.error(f"âœ— Phase 3 test FAILED: {e}")
            self.results['phase3'] = False
            return False
    
    def test_phase4_hvn_refinement(self) -> bool:
        """Test HVN level filtering"""
        try:
            # Create sample volume profile
            self.phase4.volume_profile = {
                100.0: 10000000,  # Major HVN
                101.0: 5000000,   # Medium
                102.0: 1000000,   # Minor
                99.0: 8000000,    # Major HVN
            }
            
            major_hvns = self.phase4.identify_major_hvns()
            assert len(major_hvns) > 0, "No major HVNs identified"
            assert 100.0 in major_hvns or 99.0 in major_hvns, "Expected HVN not found"
            
            logger.debug("Phase 4 HVN refinement test PASSED")
            self.results['phase4'] = True
            return True
        
        except AssertionError as e:
            logger.error(f"âœ— Phase 4 test FAILED: {e}")
            self.results['phase4'] = False
            return False
    
    def test_phase5_microstructure(self) -> bool:
        """Test advanced microstructure analysis"""
        try:
            # Test order flow momentum
            sample_trades = [
                {'price': 100.0, 'volume': 1000, 'side': 'buy', 'timestamp': time.time()},
                {'price': 100.1, 'volume': 1500, 'side': 'buy', 'timestamp': time.time() + 1},
                {'price': 100.2, 'volume': 800, 'side': 'sell', 'timestamp': time.time() + 2}
            ]
            
            momentum = self.phase5.calculate_order_flow_momentum(sample_trades)
            assert isinstance(momentum, (int, float)), "Momentum should be numeric"
            assert -1.0 <= momentum <= 1.0, "Momentum should be normalized"
            
            logger.debug("Phase 5 microstructure analysis test PASSED")
            self.results['phase5'] = True
            return True
        
        except Exception as e:
            logger.error(f"âœ— Phase 5 test FAILED: {e}")
            self.results['phase5'] = False
            return False
    
    def run_all_tests(self) -> Dict[str, bool]:
        """Run all phase integration tests"""
        logger.debug("Running integrated phases validation...")
        
        test_results = {
            'phase2': self.test_phase2_regime_filter(),
            'phase3': self.test_phase3_delta_divergence(), 
            'phase4': self.test_phase4_hvn_refinement(),
            'phase5': self.test_phase5_microstructure()
        }
        
        passed = sum(test_results.values())
        total = len(test_results)
        
        logger.debug(f"Integration tests completed: {passed}/{total} passed")
        
        if passed == total:
            logger.debug("ALL PHASES INTEGRATION VALIDATED")
        else:
            logger.warning(f"âš  {total - passed} phase(s) failed validation")
        
        return test_results

def initialize_all_phases():
    """Initialize and validate all development phases"""
    logger.debug("Initializing all liquidity traps development phases...")
    
    # Initialize Phase 1 (Foundation)
    initialize_phase1()
    
    # Run integrated validation
    validator = PhasesIntegratedValidation()
    results = validator.run_all_tests()
    
    # Summary
    if all(results.values()):
        logger.info("Liquidity Traps Strategy ready for production deployment")
    else:
        logger.warning("âš  Some phases failed validation - review required")
    
    return results


# ============================================================================
# MAIN EXECUTION - Initialize all phases when module loads
# ============================================================================

if __name__ == "__main__":
    initialize_all_phases()

# ============================================================================
# END OF LIQUIDITY_TRAPS STRATEGY - NEXUS AI COMPLIANT
# ============================================================================
