#!/usr/bin/env python3
"""
Comprehensive Test Suite for Spoofing Detection Strategy - Live Trading Readiness
Tests all critical components to ensure 100% readiness for live market deployment.

Test Categories:
1. Signal Generation Tests
2. Risk Management Tests  
3. Performance Validation Tests
4. NEXUS Pipeline Integration Tests
5. Critical Fixes Validation Tests
6. Live Market Simulation Tests
7. Stress Testing
8. Error Handling Tests

Author: NEXUS Trading System
Version: 1.0 Live Ready
"""

import sys
import os
import time
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Any
import unittest
import asyncio
import threading
from concurrent.futures import ThreadPoolExecutor
import logging

# Import the strategy
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# Import with proper module name (space replaced with underscore)
import importlib.util
spec = importlib.util.spec_from_file_location("spoofing_detection", "Spoofing Detection Strategy.py")
spoofing_module = importlib.util.module_from_spec(spec)
spec.loader.exec_module(spoofing_module)

# Import classes from the loaded module
UniversalStrategyConfig = spoofing_module.UniversalStrategyConfig
EnhancedSpoofingDetectionStrategy = spoofing_module.EnhancedSpoofingDetectionStrategy
SpoofingDetectionNexusAdapter = spoofing_module.SpoofingDetectionNexusAdapter
MarketData = spoofing_module.MarketData
Signal = spoofing_module.Signal
SignalType = spoofing_module.SignalType

# Configure logging for tests
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LiveTradingReadinessTests(unittest.TestCase):
    """Comprehensive test suite for live trading readiness"""
    
    def setUp(self):
        """Set up test environment"""
        self.config = UniversalStrategyConfig("spoofing_detection_test")
        self.strategy = EnhancedSpoofingDetectionStrategy(self.config)
        self.adapter = SpoofingDetectionNexusAdapter(self.strategy)
        
        # Test market data samples
        self.sample_market_data = {
            "symbol": "ES",
            "price": 4500.25,
            "bid": 4500.00,
            "ask": 4500.50,
            "bid_size": 100,
            "ask_size": 120,
            "volume": 5000,
            "timestamp": time.time(),
            "open": 4499.75,
            "close": 4500.25,
            "high": 4501.00,
            "low": 4499.50,
            "delta": 50,
            "volatility": 0.02,
            "trader_id": "test_trader_001"
        }
        
        logger.info("‚úÖ Test environment initialized")
    
    # ========== 1. SIGNAL GENERATION TESTS ==========
    
    def test_signal_generation_basic(self):
        """Test basic signal generation functionality"""
        logger.info("üß™ Testing basic signal generation...")
        
        result = self.adapter.execute(self.sample_market_data)
        
        # Validate return format
        self.assertIsInstance(result, dict)
        self.assertIn('signal', result)
        self.assertIn('confidence', result)
        self.assertIn('action', result)
        
        # Validate signal range
        signal = result['signal']
        self.assertTrue(-2.0 <= signal <= 2.0, f"Signal {signal} out of range [-2.0, 2.0]")
        
        # Validate confidence range
        confidence = result['confidence']
        self.assertTrue(0.0 <= confidence <= 1.0, f"Confidence {confidence} out of range [0.0, 1.0]")
        
        # Validate action
        action = result['action']
        self.assertIn(action, ['BUY', 'SELL', 'HOLD'])
        
        logger.info(f"‚úÖ Signal: {signal:.3f}, Confidence: {confidence:.3f}, Action: {action}")
    
    def test_signal_generation_multiple_scenarios(self):
        """Test signal generation across multiple market scenarios"""
        logger.info("üß™ Testing signal generation across multiple scenarios...")
        
        scenarios = [
            # Normal market
            {"price": 4500.0, "volume": 1000, "volatility": 0.01},
            # High volatility
            {"price": 4520.0, "volume": 5000, "volatility": 0.05},
            # Low volume
            {"price": 4495.0, "volume": 100, "volatility": 0.008},
            # Large spread
            {"price": 4505.0, "bid": 4500.0, "ask": 4510.0, "volume": 2000},
            # Suspicious order sizes
            {"price": 4500.0, "bid_size": 10000, "ask_size": 50, "volume": 8000}
        ]
        
        signals_generated = 0
        for i, scenario in enumerate(scenarios):
            test_data = self.sample_market_data.copy()
            test_data.update(scenario)
            
            result = self.adapter.execute(test_data)
            
            # Validate each result
            self.assertIsInstance(result, dict)
            self.assertIn('signal', result)
            self.assertIn('confidence', result)
            
            if abs(result['signal']) > 0.1:  # Non-zero signal
                signals_generated += 1
            
            logger.info(f"Scenario {i+1}: Signal={result['signal']:.3f}, Confidence={result['confidence']:.3f}")
        
        logger.info(f"‚úÖ Generated signals in {signals_generated}/{len(scenarios)} scenarios")
    
    def test_confidence_threshold_validation(self):
        """Test 57% confidence threshold validation (TIER 3)"""
        logger.info("üß™ Testing 57% confidence threshold validation...")
        
        # Test with low confidence scenario
        low_confidence_data = self.sample_market_data.copy()
        low_confidence_data.update({
            "volume": 50,  # Very low volume
            "volatility": 0.001,  # Very low volatility
            "bid_size": 10,
            "ask_size": 10
        })
        
        result = self.adapter.execute(low_confidence_data)
        
        # Should be filtered out by confidence threshold
        if result['confidence'] < 0.57:
            self.assertEqual(result['action'], 'HOLD')
            logger.info(f"‚úÖ Low confidence signal correctly filtered: {result['confidence']:.3f}")
        
        # Test with high confidence scenario
        high_confidence_data = self.sample_market_data.copy()
        high_confidence_data.update({
            "volume": 10000,  # High volume
            "volatility": 0.03,  # Moderate volatility
            "bid_size": 1000,
            "ask_size": 50  # Imbalanced
        })
        
        result = self.adapter.execute(high_confidence_data)
        logger.info(f"‚úÖ High confidence scenario: {result['confidence']:.3f}")
    
    # ========== 2. RISK MANAGEMENT TESTS ==========
    
    def test_kill_switch_functionality(self):
        """Test kill switch activation and reset"""
        logger.info("üß™ Testing kill switch functionality...")
        
        # Test daily loss limit trigger
        self.adapter.daily_pnl = -6000.0  # Exceed limit
        
        result = self.adapter.execute(self.sample_market_data)
        
        self.assertTrue(result.get('kill_switch_active', False))
        self.assertEqual(result['action'], 'HOLD')
        self.assertEqual(result['signal'], 0.0)
        
        # Test reset
        self.adapter.reset_kill_switch()
        self.assertFalse(self.adapter.kill_switch_active)
        
        logger.info("‚úÖ Kill switch activation and reset working correctly")
    
    def test_var_cvar_calculation(self):
        """Test VaR and CVaR risk calculations"""
        logger.info("üß™ Testing VaR and CVaR calculations...")
        
        # Populate returns history with sample data
        sample_returns = np.random.normal(0.001, 0.02, 100)  # 100 days of returns
        self.adapter.returns_history.extend(sample_returns)
        
        var_95 = self.adapter.calculate_var(0.95)
        var_99 = self.adapter.calculate_var(0.99)
        cvar_95 = self.adapter.calculate_cvar(0.95)
        cvar_99 = self.adapter.calculate_cvar(0.99)
        
        # VaR should be negative (representing potential loss)
        self.assertLessEqual(var_95, 0)
        self.assertLessEqual(var_99, 0)
        
        # CVaR should be more negative than VaR (worse case)
        self.assertLessEqual(cvar_95, var_95)
        self.assertLessEqual(cvar_99, var_99)
        
        logger.info(f"‚úÖ VaR 95%: {var_95:.2f}, VaR 99%: {var_99:.2f}")
        logger.info(f"‚úÖ CVaR 95%: {cvar_95:.2f}, CVaR 99%: {cvar_99:.2f}")
    
    def test_position_sizing_logic(self):
        """Test position sizing calculations"""
        logger.info("üß™ Testing position sizing logic...")
        
        # Test different confidence levels
        confidence_levels = [0.3, 0.5, 0.7, 0.9]
        
        for confidence in confidence_levels:
            # Simulate signal with different confidence
            test_data = self.sample_market_data.copy()
            
            # Mock a high-confidence signal
            if confidence > 0.6:
                test_data.update({
                    "volume": 8000,
                    "bid_size": 500,
                    "ask_size": 100
                })
            
            result = self.adapter.execute(test_data)
            
            logger.info(f"Confidence {confidence}: Signal={result['signal']:.3f}, Action={result['action']}")
        
        logger.info("‚úÖ Position sizing logic validated")
    
    # ========== 3. PERFORMANCE VALIDATION TESTS ==========
    
    def test_execution_latency(self):
        """Test execution latency requirements (<5ms average)"""
        logger.info("üß™ Testing execution latency...")
        
        latencies = []
        num_tests = 100
        
        for _ in range(num_tests):
            start_time = time.perf_counter()
            self.adapter.execute(self.sample_market_data)
            end_time = time.perf_counter()
            
            latency_ms = (end_time - start_time) * 1000
            latencies.append(latency_ms)
        
        avg_latency = np.mean(latencies)
        p95_latency = np.percentile(latencies, 95)
        p99_latency = np.percentile(latencies, 99)
        
        # Performance requirements
        self.assertLess(avg_latency, 5.0, f"Average latency {avg_latency:.2f}ms exceeds 5ms requirement")
        self.assertLess(p95_latency, 10.0, f"P95 latency {p95_latency:.2f}ms exceeds 10ms requirement")
        
        logger.info(f"‚úÖ Avg: {avg_latency:.2f}ms, P95: {p95_latency:.2f}ms, P99: {p99_latency:.2f}ms")
    
    def test_throughput_capacity(self):
        """Test throughput capacity (>200 ops/second)"""
        logger.info("üß™ Testing throughput capacity...")
        
        num_operations = 1000
        start_time = time.perf_counter()
        
        for i in range(num_operations):
            # Vary the data slightly to simulate real conditions
            test_data = self.sample_market_data.copy()
            test_data['price'] += np.random.uniform(-1.0, 1.0)
            test_data['timestamp'] = time.time()
            
            self.adapter.execute(test_data)
        
        end_time = time.perf_counter()
        duration = end_time - start_time
        throughput = num_operations / duration
        
        self.assertGreater(throughput, 200, f"Throughput {throughput:.1f} ops/sec below 200 requirement")
        
        logger.info(f"‚úÖ Throughput: {throughput:.1f} operations/second")
    
    def test_memory_usage_stability(self):
        """Test memory usage remains stable under load"""
        logger.info("üß™ Testing memory usage stability...")
        
        import psutil
        import gc
        
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        # Run many operations
        for i in range(5000):
            test_data = self.sample_market_data.copy()
            test_data['timestamp'] = time.time() + i
            self.adapter.execute(test_data)
            
            if i % 1000 == 0:
                gc.collect()  # Force garbage collection
        
        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory
        
        # Memory increase should be reasonable (<50MB for 5000 operations)
        self.assertLess(memory_increase, 50, f"Memory increase {memory_increase:.1f}MB too high")
        
        logger.info(f"‚úÖ Memory: {initial_memory:.1f}MB ‚Üí {final_memory:.1f}MB (+{memory_increase:.1f}MB)")
    
    # ========== 4. NEXUS PIPELINE INTEGRATION TESTS ==========
    
    def test_nexus_adapter_interface(self):
        """Test NEXUS adapter interface compliance"""
        logger.info("üß™ Testing NEXUS adapter interface...")
        
        # Test required methods exist
        self.assertTrue(hasattr(self.adapter, 'execute'))
        self.assertTrue(hasattr(self.adapter, 'get_category'))
        self.assertTrue(hasattr(self.adapter, 'get_performance_metrics'))
        self.assertTrue(hasattr(self.adapter, 'record_trade_result'))
        
        # Test execute method signature
        result = self.adapter.execute(self.sample_market_data)
        self.assertIsInstance(result, dict)
        
        # Test category
        category = self.adapter.get_category()
        self.assertIsNotNone(category)
        
        # Test performance metrics
        metrics = self.adapter.get_performance_metrics()
        self.assertIsInstance(metrics, dict)
        self.assertIn('total_trades', metrics)
        self.assertIn('win_rate', metrics)
        
        logger.info("‚úÖ NEXUS adapter interface compliant")
    
    def test_thread_safety(self):
        """Test thread safety under concurrent access"""
        logger.info("üß™ Testing thread safety...")
        
        results = []
        errors = []
        
        def worker_thread(thread_id):
            try:
                for i in range(50):
                    test_data = self.sample_market_data.copy()
                    test_data['timestamp'] = time.time() + thread_id * 1000 + i
                    result = self.adapter.execute(test_data)
                    results.append(result)
            except Exception as e:
                errors.append(f"Thread {thread_id}: {str(e)}")
        
        # Run 10 concurrent threads
        threads = []
        for i in range(10):
            thread = threading.Thread(target=worker_thread, args=(i,))
            threads.append(thread)
            thread.start()
        
        # Wait for all threads to complete
        for thread in threads:
            thread.join()
        
        # Validate results
        self.assertEqual(len(errors), 0, f"Thread safety errors: {errors}")
        self.assertEqual(len(results), 500)  # 10 threads * 50 operations
        
        logger.info(f"‚úÖ Thread safety validated: {len(results)} operations, {len(errors)} errors")
    
    # ========== 5. CRITICAL FIXES VALIDATION TESTS ==========
    
    def test_adversarial_training_robustness(self):
        """Test W1.1: Adversarial training robustness"""
        logger.info("üß™ Testing adversarial training robustness...")
        
        # Test robustness against adversarial attacks
        def mock_model_function(data):
            return self.adapter.execute(data)
        
        robustness_result = self.adapter.adversarial_trainer.test_robustness(
            mock_model_function, self.sample_market_data
        )
        
        self.assertIsInstance(robustness_result, dict)
        self.assertIn('avg_robustness_score', robustness_result)
        self.assertIn('is_robust', robustness_result)
        
        robustness_score = robustness_result['avg_robustness_score']
        self.assertGreaterEqual(robustness_score, 0.0)
        self.assertLessEqual(robustness_score, 1.0)
        
        logger.info(f"‚úÖ Adversarial robustness score: {robustness_score:.3f}")
    
    def test_chi_square_statistical_validation(self):
        """Test W1.3: Chi-square statistical validation"""
        logger.info("üß™ Testing chi-square statistical validation...")
        
        # Generate sample order events
        order_events = []
        for i in range(50):
            event = {
                'type': 'cancel' if i % 3 == 0 else 'add',
                'lifetime': np.random.exponential(2.0),  # Exponential distribution
                'size': np.random.randint(100, 1000),
                'timestamp': time.time() + i
            }
            order_events.append(event)
        
        # Test chi-square validation
        validation_result = self.adapter.chi_square_tester.validate_spoofing_pattern(order_events)
        
        self.assertIsInstance(validation_result, dict)
        self.assertIn('is_anomalous', validation_result)
        
        logger.info(f"‚úÖ Chi-square validation: {validation_result}")
    
    def test_cross_exchange_coordination_detection(self):
        """Test W2.1: Cross-exchange coordination detection"""
        logger.info("üß™ Testing cross-exchange coordination detection...")
        
        # Simulate order events from multiple exchanges
        exchanges = ['BINANCE', 'COINBASE', 'KRAKEN']
        
        for exchange in exchanges:
            for i in range(10):
                order_event = {
                    'timestamp': time.time() + i * 0.1,  # Close timing
                    'type': 'add',
                    'size': 1000,
                    'price': 4500.0 + i * 0.1,
                    'order_id': f'{exchange}_{i}'
                }
                self.adapter.cross_exchange_analyzer.add_exchange_data(exchange, order_event)
        
        # Test coordination detection
        coordination_result = self.adapter.cross_exchange_analyzer.detect_cross_exchange_coordination()
        
        self.assertIsInstance(coordination_result, dict)
        self.assertIn('is_coordinated', coordination_result)
        self.assertIn('correlation', coordination_result)
        
        logger.info(f"‚úÖ Cross-exchange coordination: {coordination_result}")
    
    def test_trader_reputation_system(self):
        """Test W2.2: Trader reputation system"""
        logger.info("üß™ Testing trader reputation system...")
        
        trader_id = "test_trader_suspicious"
        
        # Simulate suspicious trading activity
        for i in range(20):
            event = {
                'type': 'cancel' if i % 2 == 0 else 'add',  # High cancel rate
                'timestamp': time.time() + i,
                'size': 1000,
                'price': 4500.0
            }
            self.adapter.trader_reputation.update_trader_activity(trader_id, event)
        
        # Record manipulation events
        self.adapter.trader_reputation.record_manipulation_event(trader_id, 'spoofing', 0.8)
        self.adapter.trader_reputation.record_manipulation_event(trader_id, 'layering', 0.7)
        
        # Test reputation scoring
        risk_score = self.adapter.trader_reputation.get_trader_risk_score(trader_id)
        is_repeat_offender = self.adapter.trader_reputation.is_repeat_offender(trader_id)
        
        self.assertGreaterEqual(risk_score, 0.0)
        self.assertLessEqual(risk_score, 1.0)
        self.assertIsInstance(is_repeat_offender, bool)
        
        logger.info(f"‚úÖ Trader risk score: {risk_score:.3f}, Repeat offender: {is_repeat_offender}")
    
    # ========== 6. LIVE MARKET SIMULATION TESTS ==========
    
    def test_live_market_simulation(self):
        """Test with realistic live market data simulation"""
        logger.info("üß™ Testing live market simulation...")
        
        # Generate realistic market data sequence
        base_price = 4500.0
        signals_generated = []
        
        for i in range(100):
            # Simulate price movement
            price_change = np.random.normal(0, 0.5)
            base_price += price_change
            
            # Simulate volume and order book
            volume = max(100, int(np.random.lognormal(7, 1)))
            bid_size = max(10, int(np.random.lognormal(5, 0.5)))
            ask_size = max(10, int(np.random.lognormal(5, 0.5)))
            
            market_data = {
                "symbol": "ES",
                "price": base_price,
                "bid": base_price - 0.25,
                "ask": base_price + 0.25,
                "bid_size": bid_size,
                "ask_size": ask_size,
                "volume": volume,
                "timestamp": time.time() + i,
                "volatility": min(0.05, abs(price_change) / base_price * 100),
                "trader_id": f"trader_{i % 10}"
            }
            
            result = self.adapter.execute(market_data)
            signals_generated.append(result)
            
            # Simulate trade execution for some signals
            if abs(result['signal']) > 0.5 and result['confidence'] > 0.6:
                # Simulate trade result
                pnl = np.random.normal(10, 50)  # Random P&L
                trade_info = {
                    'pnl': pnl,
                    'signal': result['signal'],
                    'confidence': result['confidence'],
                    'entry_price': base_price,
                    'exit_price': base_price + (pnl / 100)
                }
                self.adapter.record_trade_result(trade_info)
        
        # Analyze results
        non_hold_signals = [s for s in signals_generated if s['action'] != 'HOLD']
        high_confidence_signals = [s for s in signals_generated if s['confidence'] > 0.7]
        
        logger.info(f"‚úÖ Live simulation: {len(non_hold_signals)}/{len(signals_generated)} active signals")
        logger.info(f"‚úÖ High confidence signals: {len(high_confidence_signals)}")
        
        # Validate performance metrics
        metrics = self.adapter.get_performance_metrics()
        logger.info(f"‚úÖ Final metrics: Trades={metrics['total_trades']}, Win Rate={metrics['win_rate']:.2%}")
    
    # ========== 7. STRESS TESTING ==========
    
    def test_extreme_market_conditions(self):
        """Test behavior under extreme market conditions"""
        logger.info("üß™ Testing extreme market conditions...")
        
        extreme_scenarios = [
            # Flash crash
            {"price": 4000.0, "volume": 100000, "volatility": 0.15, "bid_size": 10000, "ask_size": 5},
            # Market halt
            {"price": 4500.0, "volume": 0, "volatility": 0.0, "bid_size": 0, "ask_size": 0},
            # Extreme volatility
            {"price": 4800.0, "volume": 50000, "volatility": 0.25, "bid_size": 5000, "ask_size": 5000},
            # Liquidity crisis
            {"price": 4500.0, "volume": 10, "volatility": 0.05, "bid_size": 1, "ask_size": 1},
            # Manipulation attempt
            {"price": 4500.0, "volume": 80000, "volatility": 0.08, "bid_size": 50000, "ask_size": 10}
        ]
        
        for i, scenario in enumerate(extreme_scenarios):
            test_data = self.sample_market_data.copy()
            test_data.update(scenario)
            
            try:
                result = self.adapter.execute(test_data)
                
                # Validate response under stress
                self.assertIsInstance(result, dict)
                self.assertIn('signal', result)
                self.assertIn('confidence', result)
                
                # Should handle extreme conditions gracefully
                self.assertTrue(-2.0 <= result['signal'] <= 2.0)
                self.assertTrue(0.0 <= result['confidence'] <= 1.0)
                
                logger.info(f"Extreme scenario {i+1}: {result['action']} (conf: {result['confidence']:.3f})")
                
            except Exception as e:
                self.fail(f"Strategy failed under extreme condition {i+1}: {str(e)}")
        
        logger.info("‚úÖ Extreme market conditions handled successfully")
    
    def test_high_frequency_operations(self):
        """Test high-frequency operation stability"""
        logger.info("üß™ Testing high-frequency operations...")
        
        start_time = time.perf_counter()
        operations_count = 0
        errors_count = 0
        
        # Run for 10 seconds at maximum speed
        while time.perf_counter() - start_time < 10.0:
            try:
                test_data = self.sample_market_data.copy()
                test_data['timestamp'] = time.time()
                test_data['price'] += np.random.uniform(-0.1, 0.1)
                
                result = self.adapter.execute(test_data)
                operations_count += 1
                
                # Validate each result
                self.assertIsInstance(result, dict)
                
            except Exception as e:
                errors_count += 1
                if errors_count > 10:  # Too many errors
                    self.fail(f"High frequency test failed with {errors_count} errors")
        
        ops_per_second = operations_count / 10.0
        error_rate = errors_count / operations_count if operations_count > 0 else 1.0
        
        self.assertGreater(ops_per_second, 500, f"High frequency performance too low: {ops_per_second:.1f} ops/sec")
        self.assertLess(error_rate, 0.01, f"Error rate too high: {error_rate:.3%}")
        
        logger.info(f"‚úÖ High frequency: {ops_per_second:.1f} ops/sec, {error_rate:.3%} error rate")
    
    # ========== 8. ERROR HANDLING TESTS ==========
    
    def test_malformed_data_handling(self):
        """Test handling of malformed market data"""
        logger.info("üß™ Testing malformed data handling...")
        
        malformed_data_cases = [
            {},  # Empty dict
            {"symbol": "ES"},  # Missing required fields
            {"price": "invalid", "volume": -100},  # Invalid data types
            {"price": None, "volume": None},  # None values
            {"price": float('inf'), "volume": float('nan')},  # Invalid numbers
        ]
        
        for i, bad_data in enumerate(malformed_data_cases):
            try:
                result = self.adapter.execute(bad_data)
                
                # Should return safe default response
                self.assertIsInstance(result, dict)
                self.assertIn('signal', result)
                self.assertEqual(result['signal'], 0.0)  # Should default to HOLD
                
                logger.info(f"Malformed case {i+1}: Handled gracefully")
                
            except Exception as e:
                # Should not raise exceptions for malformed data
                self.fail(f"Strategy should handle malformed data gracefully, but raised: {str(e)}")
        
        logger.info("‚úÖ Malformed data handling validated")
    
    def test_network_timeout_simulation(self):
        """Test behavior during simulated network timeouts"""
        logger.info("üß™ Testing network timeout simulation...")
        
        # Simulate delayed data processing
        def delayed_execute():
            time.sleep(0.1)  # Simulate network delay
            return self.adapter.execute(self.sample_market_data)
        
        start_time = time.perf_counter()
        result = delayed_execute()
        end_time = time.perf_counter()
        
        # Should still return valid result despite delay
        self.assertIsInstance(result, dict)
        self.assertIn('signal', result)
        
        execution_time = (end_time - start_time) * 1000
        logger.info(f"‚úÖ Network delay simulation: {execution_time:.1f}ms execution time")
    
    def test_memory_pressure_handling(self):
        """Test behavior under memory pressure"""
        logger.info("üß™ Testing memory pressure handling...")
        
        # Create memory pressure by generating large datasets
        large_datasets = []
        
        try:
            # Generate some memory pressure
            for i in range(100):
                large_data = np.random.random((1000, 1000))  # ~8MB each
                large_datasets.append(large_data)
                
                # Test strategy execution under memory pressure
                if i % 10 == 0:
                    result = self.adapter.execute(self.sample_market_data)
                    self.assertIsInstance(result, dict)
            
            logger.info("‚úÖ Strategy stable under memory pressure")
            
        except MemoryError:
            logger.info("‚úÖ Memory pressure test completed (MemoryError expected)")
        finally:
            # Clean up
            del large_datasets
            import gc
            gc.collect()


def run_comprehensive_tests():
    """Run all comprehensive tests for live trading readiness"""
    print("=" * 80)
    print("üöÄ SPOOFING DETECTION STRATEGY - LIVE TRADING READINESS TESTS")
    print("=" * 80)
    
    # Create test suite
    test_suite = unittest.TestLoader().loadTestsFromTestCase(LiveTradingReadinessTests)
    
    # Run tests with detailed output
    runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout)
    result = runner.run(test_suite)
    
    # Print summary
    print("\n" + "=" * 80)
    print("üìä TEST SUMMARY")
    print("=" * 80)
    
    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    success_rate = ((total_tests - failures - errors) / total_tests * 100) if total_tests > 0 else 0
    
    print(f"Total Tests: {total_tests}")
    print(f"Passed: {total_tests - failures - errors}")
    print(f"Failed: {failures}")
    print(f"Errors: {errors}")
    print(f"Success Rate: {success_rate:.1f}%")
    
    if success_rate >= 95:
        print("\nüéâ STRATEGY IS 100% READY FOR LIVE TRADING!")
        print("‚úÖ All critical tests passed")
        print("‚úÖ Performance requirements met")
        print("‚úÖ Risk management validated")
        print("‚úÖ Error handling robust")
    else:
        print(f"\n‚ö†Ô∏è  STRATEGY NEEDS ATTENTION - {success_rate:.1f}% success rate")
        print("‚ùå Some tests failed - review before live deployment")
    
    print("=" * 80)
    
    return result


if __name__ == "__main__":
    # Run comprehensive test suite
    test_result = run_comprehensive_tests()
    
    # Exit with appropriate code
    exit_code = 0 if test_result.wasSuccessful() else 1
    sys.exit(exit_code)